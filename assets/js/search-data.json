{
  
    
        "post0": {
            "title": "10월 17일 숙제",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt . df = pd.DataFrame({&#39;a&#39;:[1,2,3,4],&#39;b&#39;:[2,3,4,5],&#39;c&#39;:[3,4,5,6],&#39;d&#39;:[4,5,6,7]}) df . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . 3 4 | 5 | 6 | 7 | . 아래의 결과를 관찰하고 drop의 기능을 유추하라. . (예시1) . df.drop(columns=&#39;a&#39;) . b c d . 0 2 | 3 | 4 | . 1 3 | 4 | 5 | . 2 4 | 5 | 6 | . 3 5 | 6 | 7 | . df.drop(columns=[&#39;a&#39;,&#39;b&#39;]) . c d . 0 3 | 4 | . 1 4 | 5 | . 2 5 | 6 | . 3 6 | 7 | . drop(columns=)는 열을 삭제해 준다 | . df.drop(index=0) . a b c d . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . 3 4 | 5 | 6 | 7 | . df.drop(index=range(2,4)) . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . drop(index=)는 행을 삭제해 준다. | . 문제: df 에서 a,c열을 삭제하고 첫행을 삭제하라. . df.drop(columns = [&#39;a&#39;, &#39;c&#39;], index = 0) . b d . 1 3 | 5 | . 2 4 | 6 | . 3 5 | 7 | .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/30/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%ED%96%89%EC%97%B4-%EC%82%AD%EC%A0%9C.html",
            "relUrl": "/python/2022/10/30/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%ED%96%89%EC%97%B4-%EC%82%AD%EC%A0%9C.html",
            "date": " • Oct 30, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "빅데이터 개론 4, 5 복습",
            "content": "import pandas as pd . df = pd.DataFrame( { &#39;name&#39; : [&#39;이철수&#39;, &#39;김영희&#39;, &#39;홍길동&#39;, &#39;John Smith&#39;, &#39;Mary Doe&#39;], &#39;sex&#39; : [&#39;M&#39;, &#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;F&#39;], &#39;age&#39; : [ 23, 25, 21, 33, 45], &#39;height&#39; : [153.5, 175.3, 163.4, 180.0, 165.7] } ) . df . name sex age height . 0 이철수 | M | 23 | 153.5 | . 1 김영희 | F | 25 | 175.3 | . 2 홍길동 | M | 21 | 163.4 | . 3 John Smith | M | 33 | 180.0 | . 4 Mary Doe | F | 45 | 165.7 | . df[&#39;name&#39;][0] . &#39;이철수&#39; . df[[&#39;name&#39;, &#39;age&#39;]] . name age . 0 이철수 | 23 | . 1 김영희 | 25 | . 2 홍길동 | 21 | . 3 John Smith | 33 | . 4 Mary Doe | 45 | . df.sex . 0 M 1 F 2 M 3 M 4 F Name: sex, dtype: object . df[df[&#39;sex&#39;] == &#39;M&#39;] . name sex age height . 0 이철수 | M | 23 | 153.5 | . 2 홍길동 | M | 21 | 163.4 | . 3 John Smith | M | 33 | 180.0 | . .isin &#54632;&#49688;&#51032; &#44292;&#54840; &#50504;&#50640; &#49440;&#53469;&#54624; &#47928;&#51088; &#46608;&#45716; &#49707;&#51088;&#47484; &#47532;&#49828;&#53944; &#54805;&#53468;&#47196; &#45347;&#50612;&#51456;&#45796;. . df[df[&#39;age&#39;].isin([25,33])] . name sex age height . 1 김영희 | F | 25 | 175.3 | . 3 John Smith | M | 33 | 180.0 | . df[ (df[&#39;age&#39;] &lt;= 30) | (df[&#39;height&#39;] &lt; 160.0) ] # | : 또는 . name sex age height . 0 이철수 | M | 23 | 153.5 | . 1 김영희 | F | 25 | 175.3 | . 2 홍길동 | M | 21 | 163.4 | . df_1 = df.loc[ (df[&#39;height&#39;] &gt;= 170.0) , &#39;name&#39;] df_1 . 1 김영희 3 John Smith Name: name, dtype: object . df . name sex age height . 0 이철수 | M | 23 | 153.5 | . 1 김영희 | F | 25 | 175.3 | . 2 홍길동 | M | 21 | 163.4 | . 3 John Smith | M | 33 | 180.0 | . 4 Mary Doe | F | 45 | 165.7 | . import pandas as pd . house = pd.read_csv(&quot;https://ilovedata.github.io/teaching/bigdata2/data/korea_house_data_01.csv&quot;, encoding=&quot;CP949&quot;) . house.head(10) . 시점 행정구역별(읍면동) 일반가구_계 1인 2인 3인 4인 5인 6인 7인 이상 . 0 2015 | 전국 | 19111030 | 5203440 | 4993818 | 4100979 | 3588931 | 940413 | 217474 | 65975 | . 1 2015 | 서울특별시 | 3784490 | 1115744 | 930467 | 817440 | 701945 | 169436 | 38547 | 10911 | . 2 2015 | 부산광역시 | 1335900 | 361749 | 366048 | 296742 | 238031 | 56971 | 12928 | 3431 | . 3 2015 | 대구광역시 | 928528 | 239517 | 239824 | 208795 | 184258 | 44071 | 9582 | 2481 | . 4 2015 | 인천광역시 | 1045417 | 243678 | 265079 | 245135 | 220538 | 55230 | 12253 | 3504 | . 5 2015 | 광주광역시 | 567157 | 163577 | 137662 | 115701 | 109612 | 32199 | 6647 | 1759 | . 6 2015 | 대전광역시 | 582504 | 169391 | 140603 | 122088 | 112055 | 30022 | 6489 | 1856 | . 7 2015 | 울산광역시 | 423412 | 103551 | 104101 | 100230 | 90735 | 19914 | 3851 | 1030 | . 8 2015 | 세종특별자치시 | 75219 | 21889 | 18010 | 15219 | 14560 | 4238 | 994 | 309 | . 9 2015 | 경기도 | 4384742 | 1026471 | 1062222 | 1005330 | 971146 | 246638 | 56117 | 16818 | . . house.sort_values(by = [ &#39;행정구역별(읍면동)&#39;, &#39;시점&#39;]) . 시점 행정구역별(읍면동) 일반가구_계 1인 2인 3인 4인 5인 6인 7인 이상 . 10 2015 | 강원도 | 606117 | 189379 | 178470 | 116384 | 87182 | 25922 | 6567 | 2213 | . 28 2016 | 강원도 | 616346 | 197917 | 180639 | 117408 | 86362 | 25441 | 6477 | 2102 | . 46 2017 | 강원도 | 620729 | 199645 | 187312 | 117912 | 83773 | 24178 | 6020 | 1889 | . 64 2018 | 강원도 | 628484 | 206295 | 193105 | 117713 | 81241 | 22835 | 5522 | 1773 | . 82 2019 | 강원도 | 633942 | 208857 | 200035 | 117416 | 79476 | 21560 | 5043 | 1555 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 29 2016 | 충청북도 | 617914 | 187377 | 170184 | 121917 | 99555 | 29534 | 7075 | 2272 | . 47 2017 | 충청북도 | 629073 | 195186 | 176617 | 122463 | 97422 | 28487 | 6737 | 2161 | . 65 2018 | 충청북도 | 640978 | 204109 | 183501 | 123042 | 94970 | 27286 | 6166 | 1904 | . 83 2019 | 충청북도 | 654713 | 215196 | 191655 | 123239 | 91764 | 25674 | 5503 | 1682 | . 101 2020 | 충청북도 | 678922 | 236208 | 198840 | 122347 | 91329 | 24143 | 4694 | 1361 | . 108 rows × 10 columns . house[house[&#39;시점&#39;] == 2020 ].sort_values(by = [ &#39;일반가구_계&#39;], ascending=False) #2020년 데이터만 선택, 내림차순 . 시점 행정구역별(읍면동) 일반가구_계 1인 2인 3인 4인 5인 6인 7인 이상 . 90 2020 | 전국 | 20926710 | 6643354 | 5864525 | 4200629 | 3271315 | 761417 | 147172 | 38298 | . 99 2020 | 경기도 | 5098431 | 1406010 | 1350139 | 1119823 | 951370 | 218173 | 42094 | 10822 | . 91 2020 | 서울특별시 | 3982290 | 1390701 | 1033901 | 792690 | 602791 | 130122 | 25770 | 6315 | . 92 2020 | 부산광역시 | 1405037 | 455207 | 411455 | 282233 | 203769 | 42608 | 7874 | 1891 | . 106 2020 | 경상남도 | 1350155 | 417737 | 399700 | 270061 | 205658 | 46516 | 8410 | 2073 | . 94 2020 | 인천광역시 | 1147200 | 324841 | 316387 | 251928 | 198528 | 44949 | 8440 | 2127 | . 105 2020 | 경상북도 | 1131819 | 388791 | 363061 | 202539 | 137092 | 32174 | 6388 | 1774 | . 93 2020 | 대구광역시 | 985816 | 304543 | 276237 | 205048 | 159654 | 33131 | 5976 | 1227 | . 102 2020 | 충청남도 | 892222 | 304973 | 264909 | 159754 | 121589 | 32419 | 6618 | 1960 | . 104 2020 | 전라남도 | 761518 | 256633 | 251506 | 131372 | 87883 | 26561 | 5727 | 1836 | . 103 2020 | 전라북도 | 755575 | 255269 | 233334 | 134414 | 96907 | 27962 | 5920 | 1769 | . 101 2020 | 충청북도 | 678922 | 236208 | 198840 | 122347 | 91329 | 24143 | 4694 | 1361 | . 100 2020 | 강원도 | 661039 | 231371 | 206755 | 117504 | 79073 | 20669 | 4409 | 1258 | . 96 2020 | 대전광역시 | 631208 | 228842 | 164795 | 116989 | 93698 | 21883 | 4034 | 967 | . 95 2020 | 광주광역시 | 599217 | 193948 | 162403 | 115978 | 97323 | 24613 | 4011 | 941 | . 97 2020 | 울산광역시 | 444087 | 122848 | 123591 | 99739 | 79489 | 15447 | 2398 | 575 | . 107 2020 | 제주특별자치도 | 263068 | 81855 | 74308 | 49903 | 38747 | 13719 | 3380 | 1156 | . 98 2020 | 세종특별자치시 | 139106 | 43577 | 33204 | 28307 | 26415 | 6328 | 1029 | 246 | . . &#54665;&#44284; &#50676; &#49325;&#51228;&#54616;&#44592; . house.drop(columns = [&quot;일반가구_계&quot;], inplace= True) house . 시점 행정구역별(읍면동) 1인 2인 3인 4인 5인 6인 7인 이상 . 0 2015 | 전국 | 5203440 | 4993818 | 4100979 | 3588931 | 940413 | 217474 | 65975 | . 1 2015 | 서울특별시 | 1115744 | 930467 | 817440 | 701945 | 169436 | 38547 | 10911 | . 2 2015 | 부산광역시 | 361749 | 366048 | 296742 | 238031 | 56971 | 12928 | 3431 | . 3 2015 | 대구광역시 | 239517 | 239824 | 208795 | 184258 | 44071 | 9582 | 2481 | . 4 2015 | 인천광역시 | 243678 | 265079 | 245135 | 220538 | 55230 | 12253 | 3504 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 103 2020 | 전라북도 | 255269 | 233334 | 134414 | 96907 | 27962 | 5920 | 1769 | . 104 2020 | 전라남도 | 256633 | 251506 | 131372 | 87883 | 26561 | 5727 | 1836 | . 105 2020 | 경상북도 | 388791 | 363061 | 202539 | 137092 | 32174 | 6388 | 1774 | . 106 2020 | 경상남도 | 417737 | 399700 | 270061 | 205658 | 46516 | 8410 | 2073 | . 107 2020 | 제주특별자치도 | 81855 | 74308 | 49903 | 38747 | 13719 | 3380 | 1156 | . 108 rows × 9 columns . house.drop(index = house[house[&quot;행정구역별(읍면동)&quot;] == &#39;전국&#39;].index, inplace= True ) house.head(20) #특정 열에 있는 &quot;전국&quot; 문자열을 가지는 행(.index)을 전부 drop하기 . 시점 행정구역별(읍면동) 1인 2인 3인 4인 5인 6인 7인 이상 . 1 2015 | 서울특별시 | 1115744 | 930467 | 817440 | 701945 | 169436 | 38547 | 10911 | . 2 2015 | 부산광역시 | 361749 | 366048 | 296742 | 238031 | 56971 | 12928 | 3431 | . 3 2015 | 대구광역시 | 239517 | 239824 | 208795 | 184258 | 44071 | 9582 | 2481 | . 4 2015 | 인천광역시 | 243678 | 265079 | 245135 | 220538 | 55230 | 12253 | 3504 | . 5 2015 | 광주광역시 | 163577 | 137662 | 115701 | 109612 | 32199 | 6647 | 1759 | . 6 2015 | 대전광역시 | 169391 | 140603 | 122088 | 112055 | 30022 | 6489 | 1856 | . 7 2015 | 울산광역시 | 103551 | 104101 | 100230 | 90735 | 19914 | 3851 | 1030 | . 8 2015 | 세종특별자치시 | 21889 | 18010 | 15219 | 14560 | 4238 | 994 | 309 | . 9 2015 | 경기도 | 1026471 | 1062222 | 1005330 | 971146 | 246638 | 56117 | 16818 | . 10 2015 | 강원도 | 189379 | 178470 | 116384 | 87182 | 25922 | 6567 | 2213 | . 11 2015 | 충청북도 | 173598 | 167146 | 120634 | 100527 | 30110 | 7428 | 2413 | . 12 2015 | 충청남도 | 234513 | 226658 | 153585 | 128382 | 39334 | 10031 | 3682 | . 13 2015 | 전라북도 | 213750 | 209008 | 135856 | 110132 | 36433 | 9038 | 3094 | . 14 2015 | 전라남도 | 218864 | 227975 | 131454 | 96940 | 33229 | 8881 | 3269 | . 15 2015 | 경상북도 | 322569 | 320498 | 207395 | 156364 | 42161 | 10360 | 3377 | . 16 2015 | 경상남도 | 346754 | 341745 | 265127 | 228216 | 59248 | 13383 | 4014 | . 17 2015 | 제주특별자치도 | 58446 | 58302 | 43864 | 38308 | 15257 | 4378 | 1814 | . 19 2016 | 서울특별시 | 1138860 | 931262 | 816946 | 686469 | 163555 | 37153 | 10460 | . 20 2016 | 부산광역시 | 372412 | 370623 | 296627 | 233160 | 55496 | 12460 | 3392 | . 21 2016 | 대구광역시 | 247444 | 242931 | 209737 | 181468 | 42748 | 9114 | 2311 | . house.reset_index(drop=True,inplace=True) #drop=True는 행 인덱스를 재구성 할 때 인덱스를 나타내는 새로운 열을 만들지 말라는 명령이다. house.head(20) . index 시점 행정구역별(읍면동) 1인 2인 3인 4인 5인 6인 7인 이상 . 0 0 | 2015 | 서울특별시 | 1115744 | 930467 | 817440 | 701945 | 169436 | 38547 | 10911 | . 1 1 | 2015 | 부산광역시 | 361749 | 366048 | 296742 | 238031 | 56971 | 12928 | 3431 | . 2 2 | 2015 | 대구광역시 | 239517 | 239824 | 208795 | 184258 | 44071 | 9582 | 2481 | . 3 3 | 2015 | 인천광역시 | 243678 | 265079 | 245135 | 220538 | 55230 | 12253 | 3504 | . 4 4 | 2015 | 광주광역시 | 163577 | 137662 | 115701 | 109612 | 32199 | 6647 | 1759 | . 5 5 | 2015 | 대전광역시 | 169391 | 140603 | 122088 | 112055 | 30022 | 6489 | 1856 | . 6 6 | 2015 | 울산광역시 | 103551 | 104101 | 100230 | 90735 | 19914 | 3851 | 1030 | . 7 7 | 2015 | 세종특별자치시 | 21889 | 18010 | 15219 | 14560 | 4238 | 994 | 309 | . 8 8 | 2015 | 경기도 | 1026471 | 1062222 | 1005330 | 971146 | 246638 | 56117 | 16818 | . 9 9 | 2015 | 강원도 | 189379 | 178470 | 116384 | 87182 | 25922 | 6567 | 2213 | . 10 10 | 2015 | 충청북도 | 173598 | 167146 | 120634 | 100527 | 30110 | 7428 | 2413 | . 11 11 | 2015 | 충청남도 | 234513 | 226658 | 153585 | 128382 | 39334 | 10031 | 3682 | . 12 12 | 2015 | 전라북도 | 213750 | 209008 | 135856 | 110132 | 36433 | 9038 | 3094 | . 13 13 | 2015 | 전라남도 | 218864 | 227975 | 131454 | 96940 | 33229 | 8881 | 3269 | . 14 14 | 2015 | 경상북도 | 322569 | 320498 | 207395 | 156364 | 42161 | 10360 | 3377 | . 15 15 | 2015 | 경상남도 | 346754 | 341745 | 265127 | 228216 | 59248 | 13383 | 4014 | . 16 16 | 2015 | 제주특별자치도 | 58446 | 58302 | 43864 | 38308 | 15257 | 4378 | 1814 | . 17 17 | 2016 | 서울특별시 | 1138860 | 931262 | 816946 | 686469 | 163555 | 37153 | 10460 | . 18 18 | 2016 | 부산광역시 | 372412 | 370623 | 296627 | 233160 | 55496 | 12460 | 3392 | . 19 19 | 2016 | 대구광역시 | 247444 | 242931 | 209737 | 181468 | 42748 | 9114 | 2311 | . &#50676;&#51060;&#47492; &#48148;&#44984;&#44592; . house.rename( columns={ &quot;시점&quot; : &quot;year&quot;, &quot;행정구역별(읍면동)&quot; : &quot;region&quot;, &quot;1인&quot; : &quot;p1&quot;, &quot;2인&quot; : &quot;p2&quot;, &quot;3인&quot; : &quot;p3&quot;, &quot;4인&quot; : &quot;p4&quot;, &quot;5인&quot; : &quot;p5&quot;, &quot;6인&quot; : &quot;p6&quot;, &quot;7인 이상&quot; : &quot;p7plus&quot;}, inplace=True) house . house.rename(columns = { &quot;1인&quot; : &quot;p1&quot;, &quot;2인&quot; : &quot;p2&quot;}) . index 시점 행정구역별(읍면동) p1 p2 3인 4인 5인 6인 7인 이상 . 0 0 | 2015 | 서울특별시 | 1115744 | 930467 | 817440 | 701945 | 169436 | 38547 | 10911 | . 1 1 | 2015 | 부산광역시 | 361749 | 366048 | 296742 | 238031 | 56971 | 12928 | 3431 | . 2 2 | 2015 | 대구광역시 | 239517 | 239824 | 208795 | 184258 | 44071 | 9582 | 2481 | . 3 3 | 2015 | 인천광역시 | 243678 | 265079 | 245135 | 220538 | 55230 | 12253 | 3504 | . 4 4 | 2015 | 광주광역시 | 163577 | 137662 | 115701 | 109612 | 32199 | 6647 | 1759 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 97 97 | 2020 | 전라북도 | 255269 | 233334 | 134414 | 96907 | 27962 | 5920 | 1769 | . 98 98 | 2020 | 전라남도 | 256633 | 251506 | 131372 | 87883 | 26561 | 5727 | 1836 | . 99 99 | 2020 | 경상북도 | 388791 | 363061 | 202539 | 137092 | 32174 | 6388 | 1774 | . 100 100 | 2020 | 경상남도 | 417737 | 399700 | 270061 | 205658 | 46516 | 8410 | 2073 | . 101 101 | 2020 | 제주특별자치도 | 81855 | 74308 | 49903 | 38747 | 13719 | 3380 | 1156 | . 102 rows × 10 columns . &#50836;&#50557; . 정렬할 때는 sort_values() 메소드를 사용한다. . 열 또는 행을 제거할 때 drop() 메소드를 사용한다. . 열이름을 바꿀 때는 rename() 메소드를 사용한다. . 행의 인덱스를 재구성하는 경우 reset_index() 를 이용한다. . 변경된 내용을 데이터프레임에 적용하려면 inplace = True 선택문을 사용한다. . 4-3 . weather = pd.read_csv(&quot;https://ilovedata.github.io/teaching/bigdata2/data/weather_stats.csv&quot; , encoding=&quot;cp949&quot;) weather . 일시 평균기온(℃) 최고기온 평균(℃) 최저기온 평균(℃) 강수량(mm) . 0 2020년 | 13.2 | 17.9 | 9.4 | 1651.1 | . 1 2019년 | 13.5 | 18.5 | 9.3 | 891.3 | . 2 2018년 | 12.9 | 17.9 | 8.8 | 1284.1 | . 3 2017년 | 13.0 | 18.1 | 8.8 | 1233.2 | . 4 2016년 | 13.6 | 18.5 | 9.4 | 991.7 | . weather.columns = [&quot;year&quot;, &quot;avg_t&quot;, &quot;max_t&quot;, &quot;min_t&quot;, &quot;rain&quot;] #열 이름 한 꺼번에 다 바꾸고 싶을 때 사용하기 . 화씨(F)로 된 새로운 열 avg_t_F를 만들어 보자. . 𝐹=32+1.8×𝐶 . weather[&quot;avg_t_F&quot;] = 32 + 1.8*weather[&quot;avg_t&quot;] weather . year avg_t max_t min_t rain avg_t_F . 0 2020년 | 13.2 | 17.9 | 9.4 | 1651.1 | 55.76 | . 1 2019년 | 13.5 | 18.5 | 9.3 | 891.3 | 56.30 | . 2 2018년 | 12.9 | 17.9 | 8.8 | 1284.1 | 55.22 | . 3 2017년 | 13.0 | 18.1 | 8.8 | 1233.2 | 55.40 | . 4 2016년 | 13.6 | 18.5 | 9.4 | 991.7 | 56.48 | . weather[&quot;avg_t_minmix&quot;] = (weather[&quot;max_t&quot;] + weather[&quot;min_t&quot;])/2.0 weather[&quot;avg_t_minmix_2&quot;] = weather[ [&quot;max_t&quot;, &quot;min_t&quot;] ].sum(axis=1) /2.0 weather . year avg_t max_t min_t rain avg_t_F avg_t_minmix avg_t_minmix_2 . 0 2020년 | 13.2 | 17.9 | 9.4 | 1651.1 | 55.76 | 13.65 | 13.65 | . 1 2019년 | 13.5 | 18.5 | 9.3 | 891.3 | 56.30 | 13.90 | 13.90 | . 2 2018년 | 12.9 | 17.9 | 8.8 | 1284.1 | 55.22 | 13.35 | 13.35 | . 3 2017년 | 13.0 | 18.1 | 8.8 | 1233.2 | 55.40 | 13.45 | 13.45 | . 4 2016년 | 13.6 | 18.5 | 9.4 | 991.7 | 56.48 | 13.95 | 13.95 | . weather[ [&quot;max_t&quot;, &quot;min_t&quot;] ].sum(axis=0) #열(0) 1:행 . max_t 90.9 min_t 45.7 dtype: float64 . &#50676;&#51032; &#50836;&#50557; &#53685;&#44228; . weather.mean(axis=0,numeric_only=True) #mean(axis=0) 은 문자로 구성된 열을 자동적으로 제외하고 각 열의 평균을 구해준다 . avg_t 13.240 max_t 18.180 min_t 9.140 rain 1210.280 avg_t_F 55.832 avg_t_minmix 13.660 avg_t_minmix_2 13.660 dtype: float64 . weather.mean(axis=0,numeric_only=True).to_frame() #데이터 프레임으로 만들기 . 0 . avg_t 13.240 | . max_t 18.180 | . min_t 9.140 | . rain 1210.280 | . avg_t_F 55.832 | . avg_t_minmix 13.660 | . avg_t_minmix_2 13.660 | . weather.mean(axis=0,numeric_only=True).to_frame().reset_index().rename(columns={0:&quot;mean&quot;}) . index mean . 0 avg_t | 13.240 | . 1 max_t | 18.180 | . 2 min_t | 9.140 | . 3 rain | 1210.280 | . 4 avg_t_F | 55.832 | . 5 avg_t_minmix | 13.660 | . 6 avg_t_minmix_2 | 13.660 | . house = pd.read_csv(&quot;https://ilovedata.github.io/teaching/bigdata2/data/house_final.csv&quot;) . #groupby( by=...)는 데이터프레임을 물리적으로 그룹을 나누어 주는 것은 아니고 메소드에서 지정된 그룹을 데이터프레임에 적용하는 기능을 한다. house_grp = house.groupby( by=[&quot;year&quot;] ) . house_year = house_grp.sum().reset_index() house_year . year p1 p2 p3 p4 p5 p6 p7plus . 0 2015 | 5203440 | 4993818 | 4100979 | 3588931 | 940413 | 217474 | 65975 | . 1 2016 | 5397615 | 5067166 | 4151701 | 3551410 | 924373 | 211475 | 63956 | . 2 2017 | 5618677 | 5260332 | 4178641 | 3473897 | 886479 | 197517 | 58332 | . 3 2018 | 5848594 | 5445691 | 4203792 | 3396320 | 849167 | 182886 | 52738 | . 4 2019 | 6147516 | 5663330 | 4217736 | 3300114 | 801048 | 166866 | 46578 | . 5 2020 | 6643354 | 5864525 | 4200629 | 3271315 | 761417 | 147172 | 38298 | . house_year[&quot;total&quot;] = house_year.sum(axis=1) house_year . year p1 p2 p3 p4 p5 p6 p7plus total . 0 2015 | 5203440 | 4993818 | 4100979 | 3588931 | 940413 | 217474 | 65975 | 19113045 | . 1 2016 | 5397615 | 5067166 | 4151701 | 3551410 | 924373 | 211475 | 63956 | 19369712 | . 2 2017 | 5618677 | 5260332 | 4178641 | 3473897 | 886479 | 197517 | 58332 | 19675892 | . 3 2018 | 5848594 | 5445691 | 4203792 | 3396320 | 849167 | 182886 | 52738 | 19981206 | . 4 2019 | 6147516 | 5663330 | 4217736 | 3300114 | 801048 | 166866 | 46578 | 20345207 | . 5 2020 | 6643354 | 5864525 | 4200629 | 3271315 | 761417 | 147172 | 38298 | 20928730 | . house_year[&quot;total&quot;] = house_year[ [&quot;p1&quot;,&quot;p2&quot;,&quot;p3&quot;,&quot;p4&quot;,&quot;p5&quot;,&quot;p6&quot;,&quot;p7plus&quot;] ].sum(axis=1) house_year . year p1 p2 p3 p4 p5 p6 p7plus total . 0 2015 | 5203440 | 4993818 | 4100979 | 3588931 | 940413 | 217474 | 65975 | 19111030 | . 1 2016 | 5397615 | 5067166 | 4151701 | 3551410 | 924373 | 211475 | 63956 | 19367696 | . 2 2017 | 5618677 | 5260332 | 4178641 | 3473897 | 886479 | 197517 | 58332 | 19673875 | . 3 2018 | 5848594 | 5445691 | 4203792 | 3396320 | 849167 | 182886 | 52738 | 19979188 | . 4 2019 | 6147516 | 5663330 | 4217736 | 3300114 | 801048 | 166866 | 46578 | 20343188 | . 5 2020 | 6643354 | 5864525 | 4200629 | 3271315 | 761417 | 147172 | 38298 | 20926710 | . house_year[&#39;p1_percent&#39;] = house_year[&#39;p1&#39;] / house_year[&#39;total&#39;] *100 house_year . year p1 p2 p3 p4 p5 p6 p7plus total p1_percent . 0 2015 | 5203440 | 4993818 | 4100979 | 3588931 | 940413 | 217474 | 65975 | 19111030 | 27.227418 | . 1 2016 | 5397615 | 5067166 | 4151701 | 3551410 | 924373 | 211475 | 63956 | 19367696 | 27.869164 | . 2 2017 | 5618677 | 5260332 | 4178641 | 3473897 | 886479 | 197517 | 58332 | 19673875 | 28.559076 | . 3 2018 | 5848594 | 5445691 | 4203792 | 3396320 | 849167 | 182886 | 52738 | 19979188 | 29.273432 | . 4 2019 | 6147516 | 5663330 | 4217736 | 3300114 | 801048 | 166866 | 46578 | 20343188 | 30.219039 | . 5 2020 | 6643354 | 5864525 | 4200629 | 3271315 | 761417 | 147172 | 38298 | 20926710 | 31.745812 | . house_year.plot.line(x=&#39;year&#39;, y=&#39;p1_percent&#39;) . &lt;AxesSubplot:xlabel=&#39;year&#39;&gt; . df = pd.DataFrame( { &quot;school&quot; : [&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;], &quot;sex&quot; : [&quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;F&quot;], &quot;score&quot; : [100, 98, 34, 83, 56, 90, 65] }) df . school sex score . 0 A | M | 100 | . 1 A | M | 98 | . 2 A | F | 34 | . 3 A | F | 83 | . 4 B | M | 56 | . 5 B | F | 90 | . 6 B | F | 65 | . . df.groupby([&quot;school&quot;, &quot;sex&quot;]).mean().reset_index() . school sex score . 0 A | F | 58.5 | . 1 A | M | 99.0 | . 2 B | F | 77.5 | . 3 B | M | 56.0 | . &quot;p1&quot;.startswith(&#39;p&#39;) . True . &quot;year&quot;.startswith(&#39;p&#39;) . False . [ x for x in house_year.columns if x.startswith(&#39;p&#39;) ] . [&#39;p1&#39;, &#39;p2&#39;, &#39;p3&#39;, &#39;p4&#39;, &#39;p5&#39;, &#39;p6&#39;, &#39;p7plus&#39;, &#39;p1_percent&#39;] . &#45936;&#51060;&#53552; &#54532;&#47112;&#51076; &#44208;&#54633; . df1 = pd.DataFrame({ &quot;name&quot; : [&quot;철수&quot;, &quot;영이&quot;, &quot;John&quot;], &quot;age&quot; : [23, 34, 19] }) df1 . name age . 0 철수 | 23 | . 1 영이 | 34 | . 2 John | 19 | . df2 = pd.DataFrame({ &quot;name&quot; : [&quot;철수&quot;, &quot;영이&quot;, &quot;John&quot;], &quot;sex&quot; : [&quot;M&quot;, &quot;F&quot;, &quot;M&quot;] }) df2 . name sex . 0 철수 | M | . 1 영이 | F | . 2 John | M | . import numpy as np import pandas as pd . np.concatenate([df1, df2], axis = 0) . array([[&#39;철수&#39;, 23], [&#39;영이&#39;, 34], [&#39;John&#39;, 19], [&#39;철수&#39;, &#39;M&#39;], [&#39;영이&#39;, &#39;F&#39;], [&#39;John&#39;, &#39;M&#39;]], dtype=object) . pd.merge(df1, df2, on=&quot;name&quot;) . name age sex . 0 철수 | 23 | M | . 1 영이 | 34 | F | . 2 John | 19 | M | . df3 = pd.DataFrame({ &quot;name&quot; : [&quot;철수&quot;, &quot;영이&quot;], &quot;weight&quot; : [55, 44] }) df3 . name weight . 0 철수 | 55 | . 1 영이 | 44 | . pd.merge(df1, df3, on=&quot;name&quot;) #식별자, 조건을 안 주면 공통된 식별자만 데이터 프레임으로 만든다 . name age weight . 0 철수 | 23 | 55 | . 1 영이 | 34 | 44 | . pd.merge(df1, df3, on=&quot;name&quot;, how=&#39;left&#39;) #df1(왼쪽 데이터 자료)에 있는 식별자 다 뽑음 . name age weight . 0 철수 | 23 | 55.0 | . 1 영이 | 34 | 44.0 | . 2 John | 19 | NaN | . df4 = pd.DataFrame({ &quot;name&quot; : [&quot;철수&quot;, &quot;영이&quot;, &quot;흥민&quot;], &quot;height&quot; : [167, 175, 183] }) df4 . name height . 0 철수 | 167 | . 1 영이 | 175 | . 2 흥민 | 183 | . pd.merge(df1, df4, on=&quot;name&quot;, how=&#39;right&#39;) # 식별자는 오른쪽 데이터프레임만 있는 것으로 . name age height . 0 철수 | 23.0 | 167 | . 1 영이 | 34.0 | 175 | . 2 흥민 | NaN | 183 | . pd.merge(df1, df4, on=&quot;name&quot;, how=&#39;inner&#39;) # 식별자는 두 데이터프레임에 공통인 것 . name age height . 0 철수 | 23 | 167 | . 1 영이 | 34 | 175 | . pd.merge(df1, df4, on=&quot;name&quot;, how=&#39;outer&#39;) # 식별자는 두 데이터프레임의 모든 것 . name age height . 0 철수 | 23.0 | 167.0 | . 1 영이 | 34.0 | 175.0 | . 2 John | 19.0 | NaN | . 3 흥민 | NaN | 183.0 | . house = pd.read_csv(&quot;https://ilovedata.github.io/teaching/bigdata2/data/korea_house_data_01.csv&quot;, encoding=&quot;CP949&quot;) . house.head(5) . 시점 행정구역별(읍면동) 일반가구_계 1인 2인 3인 4인 5인 6인 7인 이상 . 0 2015 | 전국 | 19111030 | 5203440 | 4993818 | 4100979 | 3588931 | 940413 | 217474 | 65975 | . 1 2015 | 서울특별시 | 3784490 | 1115744 | 930467 | 817440 | 701945 | 169436 | 38547 | 10911 | . 2 2015 | 부산광역시 | 1335900 | 361749 | 366048 | 296742 | 238031 | 56971 | 12928 | 3431 | . 3 2015 | 대구광역시 | 928528 | 239517 | 239824 | 208795 | 184258 | 44071 | 9582 | 2481 | . 4 2015 | 인천광역시 | 1045417 | 243678 | 265079 | 245135 | 220538 | 55230 | 12253 | 3504 | . . house.drop(columns = [&quot;일반가구_계&quot;], inplace = True) house.drop(index = house[house[&quot;행정구역별(읍면동)&quot;] == &quot;전국&quot;].index, inplace = True) . house.rename( columns={ &quot;시점&quot; : &quot;year&quot;, &quot;행정구역별(읍면동)&quot; : &quot;region&quot;, &quot;1인&quot; : &quot;p1&quot;, &quot;2인&quot; : &quot;p2&quot;, &quot;3인&quot; : &quot;p3&quot;, &quot;4인&quot; : &quot;p4&quot;, &quot;5인&quot; : &quot;p5&quot;, &quot;6인&quot; : &quot;p6&quot;, &quot;7인 이상&quot; : &quot;p7plus&quot;}, inplace=True) . house.head(5) . year region p1 p2 p3 p4 p5 p6 p7plus . 1 2015 | 서울특별시 | 1115744 | 930467 | 817440 | 701945 | 169436 | 38547 | 10911 | . 2 2015 | 부산광역시 | 361749 | 366048 | 296742 | 238031 | 56971 | 12928 | 3431 | . 3 2015 | 대구광역시 | 239517 | 239824 | 208795 | 184258 | 44071 | 9582 | 2481 | . 4 2015 | 인천광역시 | 243678 | 265079 | 245135 | 220538 | 55230 | 12253 | 3504 | . 5 2015 | 광주광역시 | 163577 | 137662 | 115701 | 109612 | 32199 | 6647 | 1759 | . house_final =house.groupby( by=[&quot;year&quot;] ).sum().reset_index() . house_final[&#39;house_total&#39;] = house_final[ [ &quot;p1&quot;,&quot;p2&quot;,&quot;p3&quot;,&quot;p4&quot;,&quot;p5&quot;,&quot;p6&quot;,&quot;p7plus&quot;] ].sum(axis=1) . house_final . year p1 p2 p3 p4 p5 p6 p7plus house_total . 0 2015 | 5203440 | 4993818 | 4100979 | 3588931 | 940413 | 217474 | 65975 | 19111030 | . 1 2016 | 5397615 | 5067166 | 4151701 | 3551410 | 924373 | 211475 | 63956 | 19367696 | . 2 2017 | 5618677 | 5260332 | 4178641 | 3473897 | 886479 | 197517 | 58332 | 19673875 | . 3 2018 | 5848594 | 5445691 | 4203792 | 3396320 | 849167 | 182886 | 52738 | 19979188 | . 4 2019 | 6147516 | 5663330 | 4217736 | 3300114 | 801048 | 166866 | 46578 | 20343188 | . 5 2020 | 6643354 | 5864525 | 4200629 | 3271315 | 761417 | 147172 | 38298 | 20926710 | . pop = pd.read_csv(&quot;https://ilovedata.github.io/teaching/bigdata2/data/korea_population_data_01.csv&quot;, encoding=&quot;CP949&quot;) . print(pop) . 시점 행정구역별(읍면동) 남자(명) 여자(명) 0 2015 서울특별시 4859535 5044777 1 2015 부산광역시 1701347 1747390 2 2015 대구광역시 1228511 1237541 3 2015 인천광역시 1455017 1435434 4 2015 광주광역시 748867 754014 .. ... ... ... ... 97 2020 전라북도 899058 903708 98 2020 전라남도 903281 885526 99 2020 경상북도 1338823 1305934 100 2020 경상남도 1692212 1640844 101 2020 제주특별자치도 338173 332685 [102 rows x 4 columns] . pop.rename( columns={ &quot;시점&quot; : &quot;year&quot;, &quot;행정구역별(읍면동)&quot; : &quot;region&quot;, &quot;남자(명)&quot; : &quot;male&quot;, &quot;여자(명)&quot; : &quot;female&quot;}, inplace=True) . . pop_final = pop.groupby(&quot;year&quot;).sum().reset_index() #연도별로 합을 구한 걸 피날에다가 저장 -&gt; 그 다음으로 토탈 열을 구하는 것을 해야함 . print(pop_final) #sum 함수를 사용하면 문자열을 배제해줌 . year male female 0 2015 25608502 25460873 1 2016 25696987 25572567 2 2017 25768055 25654452 3 2018 25877195 25752317 4 2019 25952070 25827133 5 2020 25915207 25913929 . pop_final[&quot;pop_total&quot;] = pop_final[[&quot;male&quot;, &quot;female&quot;]].sum(axis=1) . pop_final . year male female pop_total . 0 2015 | 25608502 | 25460873 | 51069375 | . 1 2016 | 25696987 | 25572567 | 51269554 | . 2 2017 | 25768055 | 25654452 | 51422507 | . 3 2018 | 25877195 | 25752317 | 51629512 | . 4 2019 | 25952070 | 25827133 | 51779203 | . 5 2020 | 25915207 | 25913929 | 51829136 | . all_final = pd.merge(house_final[[&#39;year&#39;, &#39;house_total&#39;]], pop_final[[&#39;year&#39;,&#39;pop_total&#39;]], on = &#39;year&#39;) . all_final . year house_total pop_total . 0 2015 | 19111030 | 51069375 | . 1 2016 | 19367696 | 51269554 | . 2 2017 | 19673875 | 51422507 | . 3 2018 | 19979188 | 51629512 | . 4 2019 | 20343188 | 51779203 | . 5 2020 | 20926710 | 51829136 | . all_final[&quot;avg_person_per_house&quot;] = all_final[&quot;pop_total&quot;] / all_final[&quot;house_total&quot;] . all_final.plot.line(x=&#39;year&#39;, y=&#39;avg_person_per_house&#39;) . &lt;AxesSubplot:xlabel=&#39;year&#39;&gt; . &#52309;&#53552; 5 . import matplotlib.pyplot as plt from matplotlib import rc %matplotlib inline plt.rc(&#39;font&#39;, family=&#39;NanumBarunGothic&#39;) # clolab 에서 한글 사용 plt.rcParams[&#39;axes.unicode_minus&#39;] = False plt.rcParams[&quot;figure.figsize&quot;] = (8,8) # 그림 크기 조정 import pandas as pd . physical_data = pd.read_csv(&quot;https://ilovedata.github.io/teaching/bigdata2/data/physical_test_2018_data.csv&quot;,sep=&#39;,&#39;, encoding = &#39;utf-8-sig&#39;) . physical_names = pd.read_csv(&quot;https://ilovedata.github.io/teaching/bigdata2/data/physical_test_2018_names.csv&quot;, sep=&#39;,&#39;, encoding = &#39;utf-8-sig&#39;) . physical_data.loc[:,&quot;CENTER_NM&quot;] = physical_data.loc[:,&quot;CENTER_NM&quot;].astype(&quot;category&quot;) physical_data.loc[:,&quot;CERT_GBN&quot;] = physical_data.loc[:, &quot;CERT_GBN&quot;].astype(&quot;category&quot;) physical_data.loc[:,&quot;AGE_GBN&quot;] = physical_data.loc[:, &quot;AGE_GBN&quot;].astype(&quot;category&quot;) physical_data.loc[:,&quot;TEST_SEX&quot; ] = physical_data.loc[:, &quot;TEST_SEX&quot;].astype(&quot;category&quot;) . physical_data[&quot;TEST_SEX&quot;].value_counts() . M 1081 F 793 Name: TEST_SEX, dtype: int64 . physical_data[&quot;TEST_SEX&quot;].value_counts().plot.pie() . &lt;AxesSubplot:ylabel=&#39;TEST_SEX&#39;&gt; . findfont: Font family [&#39;NanumBarunGothic&#39;] not found. Falling back to DejaVu Sans. . . import seaborn as sns sns.scatterplot(data=physical_data, x=&#39;ITEM_F001&#39;,y= &#39;ITEM_F002&#39;,hue=&#39;TEST_SEX&#39;, alpha=0.5) . &lt;AxesSubplot:xlabel=&#39;ITEM_F001&#39;, ylabel=&#39;ITEM_F002&#39;&gt; . sns.displot(data=physical_data, x=&quot;ITEM_F002&quot;, hue=&quot;TEST_SEX&quot;) . &lt;seaborn.axisgrid.FacetGrid at 0x7fbbf32ceb80&gt; . sns.catplot(data=physical_data, x=&#39;TEST_SEX&#39;,y= &#39;ITEM_F002&#39;, kind=&quot;box&quot; ) . &lt;seaborn.axisgrid.FacetGrid at 0x7fbbe3da0520&gt; . import pandas as pd import seaborn as sns import numpy as np from scipy.stats import norm # 정규분포 import matplotlib.pyplot as plt # 그래프 그리기를 위한 라이브러리 .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/29/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B0%9C%EB%A1%A0-4,-5-,-sortvalues,-merge(on-=,-how-),-%ED%96%89%EC%97%B4%EC%82%AD%EC%A0%9C,-sns,.html",
            "relUrl": "/python/2022/10/29/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B0%9C%EB%A1%A0-4,-5-,-sortvalues,-merge(on-=,-how-),-%ED%96%89%EC%97%B4%EC%82%AD%EC%A0%9C,-sns,.html",
            "date": " • Oct 29, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "2",
            "content": "import pandas as pd import seaborn as sns import numpy as np from scipy.stats import norm # 정규분포 import matplotlib.pyplot as plt . dset = pd.read_csv(&quot;./exam.csv&quot;) rset = pd.read_csv(&quot;./report.csv&quot;) . print(dset) . id sex midterm final 0 1 M 79 90 1 2 F 81 77 2 3 F 56 56 3 4 M 90 78 4 5 F 77 65 5 6 F 89 70 6 7 M 45 60 7 8 M 65 70 8 9 F 59 77 9 10 F 70 80 . dset.iloc[4,2] . 77 . dset[&quot;total&quot;] = dset[&quot;midterm&quot;]*0.6 + dset[&quot;final&quot;]*0.4 print(dset) . id sex midterm final total 0 1 M 79 90 83.4 1 2 F 81 77 79.4 2 3 F 56 56 56.0 3 4 M 90 78 85.2 4 5 F 77 65 72.2 5 6 F 89 70 81.4 6 7 M 45 60 51.0 7 8 M 65 70 67.0 8 9 F 59 77 66.2 9 10 F 70 80 74.0 . dset[&quot;sex&quot;].value_counts().plot.pie() #1-3. 성별의 분포를 나타내어라. . &lt;AxesSubplot:ylabel=&#39;sex&#39;&gt; . dset[&quot;midterm&quot;].plot.hist() . &lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt; . sns.scatterplot(data=dset, x = &#39;id&#39;, y=&#39;midterm&#39;) #중간고사 성적 산점도 . &lt;AxesSubplot:xlabel=&#39;id&#39;, ylabel=&#39;midterm&#39;&gt; . sns.scatterplot(data=dset, x = &#39;id&#39;, y=&#39;final&#39;, color = &#39;r&#39;) #기말고사성적에 대한 산점도 . &lt;AxesSubplot:xlabel=&#39;id&#39;, ylabel=&#39;final&#39;&gt; . dset.groupby(&quot;sex&quot;)[&quot;final&quot;].mean() . sex F 70.833333 M 74.500000 Name: final, dtype: float64 . print(dset) . id sex midterm final total 0 1 M 79 90 83.4 1 2 F 81 77 79.4 2 3 F 56 56 56.0 3 4 M 90 78 85.2 4 5 F 77 65 72.2 5 6 F 89 70 81.4 6 7 M 45 60 51.0 7 8 M 65 70 67.0 8 9 F 59 77 66.2 9 10 F 70 80 74.0 . a = dset.sort_values(by = &#39;total&#39;, ascending=False) a . id sex midterm final total . 3 4 | M | 90 | 78 | 85.2 | . 0 1 | M | 79 | 90 | 83.4 | . 5 6 | F | 89 | 70 | 81.4 | . 1 2 | F | 81 | 77 | 79.4 | . 9 10 | F | 70 | 80 | 74.0 | . 4 5 | F | 77 | 65 | 72.2 | . 7 8 | M | 65 | 70 | 67.0 | . 8 9 | F | 59 | 77 | 66.2 | . 2 3 | F | 56 | 56 | 56.0 | . 6 7 | M | 45 | 60 | 51.0 | . a.iloc[2,0] . 6 . dset[&quot;hak&quot;] = [ &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;,&quot;B&quot;, &quot;B&quot;,&quot;B&quot;, &quot;C&quot;, &quot;C&quot; ] # if dset[&quot;total&quot;] &gt;= 80: # print(&quot;A&quot;) # elif dset[&quot;total&quot;] &gt;= 60: # print(&quot;B&quot;) # else: # print(&quot;C&quot;) dset . id sex midterm final hak . 0 1 | M | 79 | 90 | A | . 1 2 | F | 81 | 77 | A | . 2 3 | F | 56 | 56 | A | . 3 4 | M | 90 | 78 | B | . 4 5 | F | 77 | 65 | B | . 5 6 | F | 89 | 70 | B | . 6 7 | M | 45 | 60 | B | . 7 8 | M | 65 | 70 | B | . 8 9 | F | 59 | 77 | C | . 9 10 | F | 70 | 80 | C | . dset[dset[&quot;final&quot;]&gt;= 80].mean() #1-10. 기말고사 성적이 80점 이상인 학생들만 추출하고 그에 대한 평균을 구하여라. . /var/folders/xh/xtwkcbrj0_l1srsb4r5pc3l00000gn/T/ipykernel_83787/4252691933.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with &#39;numeric_only=None&#39;) is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the reduction. dset[dset[&#34;final&#34;]&gt;= 80].mean() . id 5.5 midterm 74.5 final 85.0 total 78.7 dtype: float64 . #1-11. report.csv에는 위 exam.csv에 나타난 동일 학생들에 대한 번호(n)와 과제점수(report)가 포함되어 있다. 중간고사성적, 기말고사성적, 과제점수가 모두 포함된 데이터셋을 하나 만들어라. 단, 과제를 제출하지 않은 학생은 제외하여라. ddd = pd.DataFrame( { &quot;midterm&quot; : [79, 81, 56, 90, 89, 45, 65, 59], &quot;final&quot; : [90, 77, 56, 78, 70, 60, 70, 77], &quot;report&quot; : [70, 78, 76, 89, 91, 58, 86, 55] }, index = [1, 2, 3, 4, 6, 7, 8, 9]) ddd . midterm final report . 1 79 | 90 | 70 | . 2 81 | 77 | 78 | . 3 56 | 56 | 76 | . 4 90 | 78 | 89 | . 6 89 | 70 | 91 | . 7 45 | 60 | 58 | . 8 65 | 70 | 86 | . 9 59 | 77 | 55 | . d = dset[ dset[&#39;sex&#39;] == &#39;M&#39; ][&quot;midterm&quot;] d . 0 79 3 90 6 45 7 65 Name: midterm, dtype: int64 . df = pd.read_csv(&quot;mers_korea_2015.csv&quot;) df.head() . Unnamed: 0 id age age_class sex place_infect reporting_ctry loc_hosp dt_onset dt_report week_report dt_start_exp dt_end_exp dt_diag outcome dt_death . 0 1 | SK_1 | 68 | 60-69 | M | Middle East | South Korea | Pyeongtaek St. Mary, Hospital, Pyeongtaek, Gye... | 2015-05-11 | 2015-05-19 | 2015_21 | 2015-04-18 | 2015-05-04 | 2015-05-20 | Alive | NaN | . 1 2 | SK_2 | 63 | 60-69 | F | Outside Middle East | South Korea | Pyeongtaek St. Mary, Hospital, Pyeongtaek, Gye... | 2015-05-18 | 2015-05-20 | 2015_21 | 2015-05-15 | 2015-05-20 | 2015-05-20 | Alive | NaN | . 2 3 | SK_3 | 76 | 70-79 | M | Outside Middle East | South Korea | Pyeongtaek St. Mary, Hospital, Pyeongtaek, Gye... | 2015-05-20 | 2015-05-20 | 2015_21 | 2015-05-16 | 2015-05-16 | 2015-05-21 | Dead | 2015-06-04 | . 3 4 | SK_4 | 46 | 40-49 | F | Outside Middle East | South Korea | Pyeongtaek St. Mary, Hospital, Pyeongtaek, Gye... | 2015-05-25 | 2015-05-26 | 2015_22 | 2015-05-16 | 2015-05-20 | 2015-05-26 | Alive | NaN | . 4 5 | SK_5 | 50 | 50-59 | M | Outside Middle East | South Korea | 365 Yeollin Clinic, Seoul | 2015-05-25 | 2015-05-27 | 2015_22 | 2015-05-17 | 2015-05-17 | 2015-05-26 | Alive | NaN | . df.groupby( by=[&quot;dt_report&quot;] ) . &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f819241eb20&gt; . df.groupby( by=[&quot;age_class&quot;] ) . &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f81906c57f0&gt; . df.groupby( by=[&quot;outcome&quot;] ).age_class.describe() . count unique top freq . outcome . Alive 143 | 8 | 50-59 | 31 | . Dead 19 | 5 | 70-79 | 7 | . 3 . A = np.arange(2, 101, 2).reshape(10,5) A . array([[ 2, 4, 6, 8, 10], [ 12, 14, 16, 18, 20], [ 22, 24, 26, 28, 30], [ 32, 34, 36, 38, 40], [ 42, 44, 46, 48, 50], [ 52, 54, 56, 58, 60], [ 62, 64, 66, 68, 70], [ 72, 74, 76, 78, 80], [ 82, 84, 86, 88, 90], [ 92, 94, 96, 98, 100]]) . A[:2,] . array([[ 2, 4, 6, 8, 10], [12, 14, 16, 18, 20]]) . 4 . x = 0 for i in np.arange(1,101) : x =+ 2*i-1 x . 199 . y = 0 for i in np.arange(0,11) : for j in np.arange(1, i+1) : y += i+j y . 605 . 5 . N = 20 count_head = 0 for i in np.arange(N) : x = np.random.rand(1) if x &lt; 0.5 : count_head = count_head + 1 print(count_head/20*100) . 40.0 . N = 200 count_head = 0 for i in np.arange(N) : x = np.random.rand(1) if x &lt; 0.5 : count_head = count_head + 1 count_head #실험차수( 1,2,3,… )에 따른 앞면이 나온 비율의 변화를 그림으로 나타내어라. . 113 . 6 . A = 1000000 B = 1000000 P = 1/8 #1/16 + 1/16 for i in np.arange(10) : x = np.random.rand(1) if x &lt; 1/8 : A += 10000 B -= 10000 else : A -= 20000 B += 20000 . A = 1000000 B = 1000000 P = 1/8 #1/16 + 1/16 for i in np.arange(50) : x = np.random.rand(1) if x &lt; 1/8 : A += 10000 B -= 10000 else : A -= 20000 B += 20000 print([A,B]) . [270000, 1730000] . A = 1000000 B = 1000000 P = 1/8 #1/16 + 1/16 N = 20 for i in np.arange(20) : x = np.random.rand(1) if x &lt; 1/8 : A += 10000 B -= 10000 else : A -= 20000 B += 20000 plt.hist(x = N, y = A) . (array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([19.5, 19.6, 19.7, 19.8, 19.9, 20. , 20.1, 20.2, 20.3, 20.4, 20.5]), &lt;BarContainer object of 10 artists&gt;) .",
            "url": "https://g-gg-ggg.github.io/Oppps/2022/10/29/%EA%B0%9C%EB%A1%A0-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html",
            "relUrl": "/2022/10/29/%EA%B0%9C%EB%A1%A0-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html",
            "date": " • Oct 29, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "더하기",
            "content": "1+1 . 2 . 2+3 . 5 .",
            "url": "https://g-gg-ggg.github.io/Oppps/2022/10/29/test.html",
            "relUrl": "/2022/10/29/test.html",
            "date": " • Oct 29, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "데이터 시각화 8",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) df . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres ... num_user_for_reviews language country content_rating budget title_year actor_2_facebook_likes imdb_score aspect_ratio movie_facebook_likes . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | ... | 3054.0 | English | USA | PG-13 | 237000000.0 | 2009.0 | 936.0 | 7.9 | 1.78 | 33000 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | ... | 1238.0 | English | USA | PG-13 | 300000000.0 | 2007.0 | 5000.0 | 7.1 | 2.35 | 0 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | ... | 994.0 | English | UK | PG-13 | 245000000.0 | 2015.0 | 393.0 | 6.8 | 2.35 | 85000 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | ... | 2701.0 | English | USA | PG-13 | 250000000.0 | 2012.0 | 23000.0 | 8.5 | 2.35 | 164000 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | ... | NaN | NaN | NaN | NaN | NaN | NaN | 12.0 | 7.1 | NaN | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | ... | 6.0 | English | Canada | NaN | NaN | 2013.0 | 470.0 | 7.7 | NaN | 84 | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | ... | 359.0 | English | USA | TV-14 | NaN | NaN | 593.0 | 7.5 | 16.00 | 32000 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | ... | 3.0 | English | USA | NaN | 1400.0 | 2013.0 | 0.0 | 6.3 | NaN | 16 | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | ... | 9.0 | English | USA | PG-13 | NaN | 2012.0 | 719.0 | 6.3 | 2.35 | 660 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | ... | 84.0 | English | USA | PG | 1100.0 | 2004.0 | 23.0 | 6.6 | 1.85 | 456 | . 4916 rows × 28 columns . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . ##iloc를 사용하여 뽑고 싶을 열의 리스트를 적는다 pd.Series(df.columns) . 0 color 1 director_name 2 num_critic_for_reviews 3 duration 4 director_facebook_likes 5 actor_3_facebook_likes 6 actor_2_name 7 actor_1_facebook_likes 8 gross 9 genres 10 actor_1_name 11 movie_title 12 num_voted_users 13 cast_total_facebook_likes 14 actor_3_name 15 facenumber_in_poster 16 plot_keywords 17 movie_imdb_link 18 num_user_for_reviews 19 language 20 country 21 content_rating 22 budget 23 title_year 24 actor_2_facebook_likes 25 imdb_score 26 aspect_ratio 27 movie_facebook_likes dtype: object . list(range(13)) . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] . df.iloc[:,list(range(13))+[26]] . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres actor_1_name movie_title num_voted_users aspect_ratio . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | CCH Pounder | Avatar | 886204 | 1.78 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | Johnny Depp | Pirates of the Caribbean: At World&#39;s End | 471220 | 2.35 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | Christoph Waltz | Spectre | 275868 | 2.35 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | Tom Hardy | The Dark Knight Rises | 1144337 | 2.35 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | Doug Walker | Star Wars: Episode VII - The Force Awakens | 8 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | Eric Mabius | Signed Sealed Delivered | 629 | NaN | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | Natalie Zea | The Following | 73839 | 16.00 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | Eva Boehnke | A Plague So Pleasant | 38 | NaN | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | Alan Ruck | Shanghai Calling | 1255 | 2.35 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | John August | My Date with Drew | 4285 | 1.85 | . 4916 rows × 14 columns . actor&#46972;&#45716; &#45800;&#50612;&#44032; &#54252;&#54632;&#46108; &#50676;&#51012; &#48977;&#45716; &#48169;&#48277; . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . df.loc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] #df.loc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns))] #df.iloc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns))] #df.iloc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . s&#47196; &#45149;&#45208;&#45716; column &#49440;&#53469;&#54616;&#44592; . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . df.iloc[:,map(lambda x : &#39;s&#39; == x[-1], df.columns)] . num_critic_for_reviews director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes gross genres num_voted_users cast_total_facebook_likes plot_keywords num_user_for_reviews actor_2_facebook_likes movie_facebook_likes . 0 723.0 | 0.0 | 855.0 | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | 886204 | 4834 | avatar|future|marine|native|paraplegic | 3054.0 | 936.0 | 33000 | . 1 302.0 | 563.0 | 1000.0 | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | 471220 | 48350 | goddess|marriage ceremony|marriage proposal|pi... | 1238.0 | 5000.0 | 0 | . 2 602.0 | 0.0 | 161.0 | 11000.0 | 200074175.0 | Action|Adventure|Thriller | 275868 | 11700 | bomb|espionage|sequel|spy|terrorist | 994.0 | 393.0 | 85000 | . 3 813.0 | 22000.0 | 23000.0 | 27000.0 | 448130642.0 | Action|Thriller | 1144337 | 106759 | deception|imprisonment|lawlessness|police offi... | 2701.0 | 23000.0 | 164000 | . 4 NaN | 131.0 | NaN | 131.0 | NaN | Documentary | 8 | 143 | NaN | NaN | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 1.0 | 2.0 | 318.0 | 637.0 | NaN | Comedy|Drama | 629 | 2283 | fraud|postal worker|prison|theft|trial | 6.0 | 470.0 | 84 | . 4912 43.0 | NaN | 319.0 | 841.0 | NaN | Crime|Drama|Mystery|Thriller | 73839 | 1753 | cult|fbi|hideout|prison escape|serial killer | 359.0 | 593.0 | 32000 | . 4913 13.0 | 0.0 | 0.0 | 0.0 | NaN | Drama|Horror|Thriller | 38 | 0 | NaN | 3.0 | 0.0 | 16 | . 4914 14.0 | 0.0 | 489.0 | 946.0 | 10443.0 | Comedy|Drama|Romance | 1255 | 2386 | NaN | 9.0 | 719.0 | 660 | . 4915 43.0 | 16.0 | 16.0 | 86.0 | 85222.0 | Documentary | 4285 | 163 | actress name in title|crush|date|four word tit... | 84.0 | 23.0 | 456 | . 4916 rows × 12 columns . c &#54841;&#51008; d&#47196; &#49884;&#51089;&#54616;&#45716; column &#49440;&#53469; . df.iloc[:,map(lambda x : &#39;c&#39; == x[0] or &#39;d&#39; == x[0], df.columns)] # 람다에서 x라고 칭했으면 x에 대해서 표현하기 # or로 표현하기 . color director_name duration director_facebook_likes cast_total_facebook_likes country content_rating . 0 Color | James Cameron | 178.0 | 0.0 | 4834 | USA | PG-13 | . 1 Color | Gore Verbinski | 169.0 | 563.0 | 48350 | USA | PG-13 | . 2 Color | Sam Mendes | 148.0 | 0.0 | 11700 | UK | PG-13 | . 3 Color | Christopher Nolan | 164.0 | 22000.0 | 106759 | USA | PG-13 | . 4 NaN | Doug Walker | NaN | 131.0 | 143 | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 87.0 | 2.0 | 2283 | Canada | NaN | . 4912 Color | NaN | 43.0 | NaN | 1753 | USA | TV-14 | . 4913 Color | Benjamin Roberds | 76.0 | 0.0 | 0 | USA | NaN | . 4914 Color | Daniel Hsia | 100.0 | 0.0 | 2386 | USA | PG-13 | . 4915 Color | Jon Gunn | 90.0 | 16.0 | 163 | USA | PG | . 4916 rows × 7 columns . &#50676; &#47564;&#46308;&#44592; . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df[&#39;c&#39;]=[3,4,5] df[&#39;d&#39;]=[4,5,6] df . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . df[&#39;c&#39;], df[&#39;d&#39;]=[3,4,5],[4,5,6] df . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . &#50676; &#52628;&#44032;&#54616;&#44592; .assign . df = pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[2,3,4]}) df . a b . 0 1 | 2 | . 1 2 | 3 | . 2 3 | 4 | . df.assign(c = [3, 4, 5]) . a b c . 0 1 | 2 | 3 | . 1 2 | 3 | 4 | . 2 3 | 4 | 5 | . df.assign(c = [3, 4, 5]).assign(d=[4,5,6]) # 앞에 거는 이 전 데이터 프레임으로 돌아가지 못함. 하지만 sssign은 df를 치면 원래 데이터 모습이 나옴 . a b c d . 0 1 | 2 | 3 | 4 | . 1 2 | 3 | 4 | 5 | . 2 3 | 4 | 5 | 6 | . . df=pd.DataFrame({&#39;x&#39;:np.random.randn(1000),&#39;y&#39;:np.random.randn(1000)}) df . x y . 0 -0.976762 | 0.075777 | . 1 -0.397874 | 0.342998 | . 2 0.604644 | 0.246018 | . 3 -0.744217 | -0.277895 | . 4 2.711524 | 1.573282 | . ... ... | ... | . 995 0.213143 | -0.708180 | . 996 1.128006 | -1.885075 | . 997 -1.016861 | 1.735639 | . 998 -0.400463 | 0.718326 | . 999 -1.010429 | -0.452786 | . 1000 rows × 2 columns . df.assign(r=np.sqrt(df.x**2 + df.y**2)) . x y r . 0 -0.976762 | 0.075777 | 0.979697 | . 1 -0.397874 | 0.342998 | 0.525311 | . 2 0.604644 | 0.246018 | 0.652778 | . 3 -0.744217 | -0.277895 | 0.794408 | . 4 2.711524 | 1.573282 | 3.134897 | . ... ... | ... | ... | . 995 0.213143 | -0.708180 | 0.739559 | . 996 1.128006 | -1.885075 | 2.196794 | . 997 -1.016861 | 1.735639 | 2.011579 | . 998 -0.400463 | 0.718326 | 0.822413 | . 999 -1.010429 | -0.452786 | 1.107241 | . 1000 rows × 3 columns . df.assign(r=list(map(lambda x,y: np.sqrt(x**2+y**2), df.x,df.y))) . x y r . 0 -0.976762 | 0.075777 | 0.979697 | . 1 -0.397874 | 0.342998 | 0.525311 | . 2 0.604644 | 0.246018 | 0.652778 | . 3 -0.744217 | -0.277895 | 0.794408 | . 4 2.711524 | 1.573282 | 3.134897 | . ... ... | ... | ... | . 995 0.213143 | -0.708180 | 0.739559 | . 996 1.128006 | -1.885075 | 2.196794 | . 997 -1.016861 | 1.735639 | 2.011579 | . 998 -0.400463 | 0.718326 | 0.822413 | . 999 -1.010429 | -0.452786 | 1.107241 | . 1000 rows × 3 columns . &#45936;&#51060;&#53552; &#49884;&#44033;&#54868; 10&#50900; 19&#51068; . &#50500;&#51060;&#49828;&#53356;&#47548;&#51012; &#47566;&#51060; &#47673;&#51004;&#47732; &#44152;&#47532;&#45716; &#48337;(2) .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/29/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-8.html",
            "relUrl": "/python/2022/10/29/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-8.html",
            "date": " • Oct 29, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "빅데이터 개론 모음",
            "content": "&#54028;&#51060;&#50028; &#44592;&#52488; . 예를 들어 아르바이트 직원의 월급을 계산하는 일반적인 작업을 고려헤 보자. 먼저 시간당 임금(hour_rate)이 정해지고 다음에 근로 일수 (month_working_days) 그리고 일간 근로 시간(day_working_hours)이 나오면 세 값을 곱하여 월급이 정해진다. . 1월에 일한 철수의 월급을 계산하기 . &#45813; . hour_rate = 10000 month_working_days = 20 day_working_hours = 4 monthpay = hour_rate * month_working_days * day_working_hours monthpay . 800000 . &#45936;&#51060;&#53552; &#54532;&#47112;&#51076;/ &#49836;&#46972;&#51060;&#49905;/ &#52309;&#53552; 1 &#47928;&#51228; . 사진과 같은 데이터 프레임을 만들어라, 5*3의 데이터 프레임 형식 | 열 이름 : area, pop, den, 행 이름 : cal, Tex NY, Flor, Ill . 이 데이터 프레임의 shape을 출력하여 보아라 | 평균 면적을 계산하여라 | 인구수가 2000만명 이하인 중들을 골라내어라 또한 해당하는 주의 평균밀도를 계산하여 보아라 | 첫 3개의 행과 첫 2개의 열로 이루어진 subdataframe을 추출하여라 | NY의 인구를 추출하여라. | &#45813; . import pandas as pd . df = pd.DataFrame({ &quot;area&quot; : [423967, 695662, 141297, 170312, 149995], &quot;pop&quot; : [38332521, 26448193, 19651127, 19552860, 12882135], &quot;den&quot; : [90.000000, 38.018740, 139.076746, 114.806121, 85.883763] }, index = [&quot;Cal&quot;, &quot;Tex&quot;, &quot;NY&quot;, &quot;Flo&quot;, &quot;Ill&quot;] ) df . area pop den . Cal 423967 | 38332521 | 90.000000 | . Tex 695662 | 26448193 | 38.018740 | . NY 141297 | 19651127 | 139.076746 | . Flo 170312 | 19552860 | 114.806121 | . Ill 149995 | 12882135 | 85.883763 | . df.shape . (5, 3) . df[&quot;area&quot;].mean . &lt;bound method NDFrame._add_numeric_operations.&lt;locals&gt;.mean of Cal 423967 Tex 695662 NY 141297 Flo 170312 Ill 149995 Name: area, dtype: int64&gt; . # 또한 해당하는 주의 평균밀도를 계산하여 보아라 df[df[&quot;pop&quot;] &lt; 20000000][&quot;den&quot;].mean . &lt;bound method NDFrame._add_numeric_operations.&lt;locals&gt;.mean of NY 139.076746 Flo 114.806121 Ill 85.883763 Name: den, dtype: float64&gt; . sub = df.iloc[:3, :2] #iloc sub # df.loc[[&quot;Cal&quot;,&quot;Tex&quot;, &quot;NY&quot;]][[&quot;area&quot;, &quot;pop&quot;]] #loc # loc를 사용해서 행을 출력할 수 있다. 그리고 그 후 열로 접근 가능 # df[[&quot;area&quot;]] # only Sereies 열만 출력 가능 . 423967 . #df.loc[&quot;NY&quot;][&quot;pop&quot;] df[&quot;pop&quot;][&quot;NY&quot;] #열과 행 순, 여러개 출력하고 싶으면 loc나 iloc 사용하기 . 19651127 . &#49884;&#44033;&#54868; . import matplotlib.pyplot as plt from matplotlib import rc %matplotlib inline rc(&#39;font&#39;, family=&#39;AppleGothic&#39;) # mac os 에서만 필요, colab 에서는 불필요 plt.rcParams[&#39;axes.unicode_minus&#39;] = False plt.rcParams[&quot;figure.figsize&quot;] = (10,5) . csv 파일 불러오기 &quot;https://ilovedata.github.io/teaching/bigdata2/data/train-data-01.csv&quot; | 자료에 포함된 운행되는 열차 번호 확인, unique() 함수 사용하기(시리즈 안에 있는 원소들을 중복이 없이 유일한 값만으로 출력해 주는 함수) | 원자료에서 다음 3개의 조건을 모두 만족하는 행들을 추출해서 참과 거짓으로 구성된 3개의 시리즈를 만들어 보자. | 열차번호가 2번이다. | 출발역은 서울역이다. | 도착역은 부산역이다. | . 날짜별로 2번 열차의 서울-부산간 탑승자수를 나타내는 시계열 그림(time series plot)을 그려보자. | . 년월일로 날짜 데이터 변환해서 DATE2에 저장하기, to_datetime() 의 옵션 format=&#39;%Y%m%d&#39; 은 변환에 사용할 정수 자료의 형식이 YYYYMMDD 로 년,월,일을 연결하여 만든 숫자라고 알려주는 것이다. 새로운 변수 DATE2를 데이터프레임에 추가 | DATE2 를 아용하여 요일을 나타내는 새로운 변수 DAYOFWEEK 를 만들어 보자. dt.dayofweek | 요일별, 구간별 분석하기, 3개의 변수(요일, 출발역, 도착역)로 자료를 그룹화(grouping)하고 평균을 낸다. | 인덱스 표현하기 .reset_index(inplace = True) | 이제 원하는 출발역과 도착역을 선택하여 요일별 평균 탑승객 수를 살펴보자.아래는 서울에서 출발하여 부산에 도착하는 탑승객 수의 요일별 평균값을 구하고 그름으로 나타난 결과이다. 금요일이 다른 요일보다 현저하게 탑승객의 수가 많고 일요일이 다소 적다는 것을 알 수 있다. | &#45813; . dset = pd.read_csv(&quot;https://ilovedata.github.io/teaching/bigdata2/data/train-data-01.csv&quot;) . print(dset) . TRAIN_NO DATE STATION_DEPART STATION_ARRV NUM_PASSENGER 0 2 20190701 서울 대전 106.0 1 2 20190702 서울 대전 113.0 2 2 20190703 서울 대전 146.0 3 2 20190704 서울 대전 84.0 4 2 20190705 서울 대전 105.0 ... ... ... ... ... ... 1764 6 20190726 울산 부산 10.0 1765 6 20190727 울산 부산 6.0 1766 6 20190728 울산 부산 21.0 1767 6 20190729 울산 부산 12.0 1768 6 20190730 울산 부산 11.0 [1769 rows x 5 columns] . dset[&quot;TRAIN_NO&quot;].unique() . array([2, 5, 6]) . t1 = dset[&quot;TRAIN_NO&quot;] ==2 # -열차번호가 2번이다. t2 = dset[&quot;STATION_DEPART&quot;] == &quot;서울&quot; # 출발역은 서울역이다. t3 = dset[&quot;STATION_ARRV&quot;] == &quot;부산&quot; #도착역은 부산역이다. newdf = t1 &amp; t2 &amp; t3 newdf . 0 False 1 False 2 False 3 False 4 False ... 1764 False 1765 False 1766 False 1767 False 1768 False Length: 1769, dtype: bool . sd = dset[newdf] #데이터 셋으로 저장, . sd.plot(x = &quot;DATE&quot;, y = &quot;NUM_PASSENGER&quot;) #plot 사용하기 . &lt;AxesSubplot:xlabel=&#39;DATE&#39;&gt; . dset[&quot;DATE2&quot;] = pd.to_datetime(dset[&quot;DATE&quot;], format = &quot;%Y%m%d&quot;) print(dset) . TRAIN_NO DATE STATION_DEPART STATION_ARRV NUM_PASSENGER DATE2 0 2 20190701 서울 대전 106.0 2019-07-01 1 2 20190702 서울 대전 113.0 2019-07-02 2 2 20190703 서울 대전 146.0 2019-07-03 3 2 20190704 서울 대전 84.0 2019-07-04 4 2 20190705 서울 대전 105.0 2019-07-05 ... ... ... ... ... ... ... 1764 6 20190726 울산 부산 10.0 2019-07-26 1765 6 20190727 울산 부산 6.0 2019-07-27 1766 6 20190728 울산 부산 21.0 2019-07-28 1767 6 20190729 울산 부산 12.0 2019-07-29 1768 6 20190730 울산 부산 11.0 2019-07-30 [1769 rows x 6 columns] . # 7. 요일별, 구간별 분석하기, 3개의 변수(요일, 출발역, 도착역)로 자료를 그룹화(grouping)하고 평균을 낸다. dset[&quot;Week&quot;] = dset[&quot;DATE2&quot;].dt.dayofweek #dayofweek는 괄호 치지 말기 train_group_data = dset[ [ &#39;STATION_DEPART&#39;, &#39;STATION_ARRV&#39;,&#39;Week&#39;,&#39;NUM_PASSENGER&#39;]] dsetg = train_group_data.groupby([&#39;STATION_DEPART&#39;,&#39;STATION_ARRV&#39;,&#39;Week&#39;]).mean() . train_group_data . STATION_DEPART STATION_ARRV Week NUM_PASSENGER . 0 서울 | 대전 | 0 | 106.0 | . 1 서울 | 대전 | 1 | 113.0 | . 2 서울 | 대전 | 2 | 146.0 | . 3 서울 | 대전 | 3 | 84.0 | . 4 서울 | 대전 | 4 | 105.0 | . ... ... | ... | ... | ... | . 1764 울산 | 부산 | 4 | 10.0 | . 1765 울산 | 부산 | 5 | 6.0 | . 1766 울산 | 부산 | 6 | 21.0 | . 1767 울산 | 부산 | 0 | 12.0 | . 1768 울산 | 부산 | 1 | 11.0 | . 1769 rows × 4 columns . dsetg.reset_index(inplace = True) dsetg . STATION_DEPART STATION_ARRV Week NUM_PASSENGER . 0 광명 | 대전 | 0 | 16.300 | . 1 광명 | 대전 | 1 | 15.200 | . 2 광명 | 대전 | 2 | 20.750 | . 3 광명 | 대전 | 3 | 21.125 | . 4 광명 | 대전 | 4 | 18.125 | . ... ... | ... | ... | ... | . 219 행신 | 서울 | 2 | 12.750 | . 220 행신 | 서울 | 3 | 10.000 | . 221 행신 | 서울 | 4 | 8.250 | . 222 행신 | 서울 | 5 | 7.500 | . 223 행신 | 서울 | 6 | 5.000 | . 224 rows × 4 columns . dsetw = dsetg[(dsetg[&quot;STATION_DEPART&quot;] == &quot;서울&quot;) &amp; (dsetg[&quot;STATION_ARRV&quot;] == &quot;대전&quot;)] #그룹화 하고 평균을 낸 데이ㅓ 셋에서 원하는 것을 고르기 그룹화 안 하고 고르면 많은 데이터 들이 출력 됨 dsetw . STATION_DEPART STATION_ARRV Week NUM_PASSENGER . 84 서울 | 대전 | 0 | 99.266667 | . 85 서울 | 대전 | 1 | 112.933333 | . 86 서울 | 대전 | 2 | 117.500000 | . 87 서울 | 대전 | 3 | 120.500000 | . 88 서울 | 대전 | 4 | 99.583333 | . 89 서울 | 대전 | 5 | 102.250000 | . 90 서울 | 대전 | 6 | 102.750000 | . dsetw.plot(x = &quot;Week&quot;, y= &quot;NUM_PASSENGER&quot;) #월요일이 0 . &lt;AxesSubplot:xlabel=&#39;Week&#39;&gt; . &#53581;&#49828;&#53944; &#49836;&#46972;&#51060;&#49905; . import matplotlib.pyplot as plt from matplotlib import rc %matplotlib inline plt.rcParams[&#39;axes.unicode_minus&#39;] = False plt.rcParams[&quot;figure.figsize&quot;] = (10,5) import numpy as np import pandas as pd . import base64 import requests url_data =&quot;https://ilovedata.github.io/teaching/bigdata2/data/little-prince.txt&quot; little_prince = requests.get(url_data) little_prince = little_prince.text . csv 파일 불러오기 &quot;https://ilovedata.github.io/teaching/bigdata2/data/little-prince.txt&quot; | 챕터 나누기 little_prince_chapters = little_prince.split(&#39;어린 왕자 r n&#39;) | 문자열들로 구성된 리스트를 데이터프레임으로 변환하자. 이미 정의된 리스트는 아래와 같이 함수 pd.DataFrame() 를 이용하여 데이터프레임 final 로 만들 수 있다. 만들어진 데이터프레임 final 은 각 장에 해당하는 28개의 행과 문자열을 가지는 1개의 열로 구성된다. final = pd.DataFrame({&#39;chapters&#39;: little_prince_chapters}) | 빈도 계산 counts = final.applymap(lambda x: np.char.count(x, &quot;어린 왕자&quot;)) | little_prince_chapters = little_prince.split(&#39;어린 왕자 r n&#39;) . mychar = &quot;폭넓은 교양과 심오한 학문적 이론 및 창의적 전문기술을 지닌 지성인을 기른다. 성실한 근면을 바탕으로 책임과 의무를 다하는 건전한 인격을 갖춘 민주 시민을 기른다.&quot; mychar . &#39;폭넓은 교양과 심오한 학문적 이론 및 창의적 전문기술을 지닌 지성인을 기른다. 성실한 근면을 바탕으로 책임과 의무를 다하는 건전한 인격을 갖춘 민주 시민을 기른다.&#39; . final = pd.DataFrame({&quot;chapters&quot; : little_prince_chapters}) final . chapters . 0 r n | . 1 영어동화 (우리말 해석) r n 생텍쥐페리 r n r n r n... | . 2 r n 물론 내 그림은 실제 모습보단 덜해. 그렇다고 내 실수는 아니라고... | . 3 4장 r n r n 난 곧 아주 중요한 두 번째 사실도 알게 됐는데,... | . 4 5장 r n r n 난 매일 그 별과 떠나온 이유와 여행에 대해 알게... | . 5 6장 r n r n 아! 어린 왕자여, 난 이제야 알겠어, 조금씩, ... | . 6 7장 r n r n 다섯 째 날에도, 항상 양 덕분에, 어린 왕자의 ... | . 7 8장 r n r n 나는 곧 이 꽃에 대해 알게 되었다. 어린 왕자의... | . 8 9장 r n 내 생각에, 어린 왕자는, 철새들이 이동할 때 함께 그 별 을... | . 9 10장 r n 어린 왕자의 별 가까이에 소행성 325호, 326호, 327... | . 10 11장 r n r n 두 번째 별엔 허영심쟁이가 살고 있었어요. r ... | . 11 12장 r n r n 술꾼 r n 다음으로 간 별엔 술꾼이 살고 ... | . 12 13장 r n r n 네 번째 별엔 장사꾼이 살고 있었다. 어린 왕자... | . 13 14장 r n r n 다섯 번째 별은 좀 이상했다. 가장 작았기 때문... | . 14 15장 r n r n 여섯 번째 별은 열 배는 큰 별이었다. 거기엔 ... | . 15 16장 r n r n 그리하여 일곱 번째로 들른 별은 지구였다. r ... | . 16 17장 r n r n 뭔 말을 거창하게 하려다 보면, 허풍이 좀 들어... | . 17 18장 r n r n 어린 왕자는 사막을 거닐어보았지만 마주친 거라 ... | . 18 19장 r n r n 어린 왕자는 높은 산에 올랐다. 어린 왕자의 별... | . 19 20장 r n r n 하지만 어린 왕자는 모랫길과 바위와 눈 뿐인 곳을 한... | . 20 21장 r n r n 그런데 그때 여우가 나타났다. r n &quot;안녕... | . 21 &quot;넌 누구니?&quot;라며 어린 왕자가 말했다. &quot;근데 넌 참 귀엽구나...&quot; r ... | . 22 22장 r n r n &quot;안녕하세요.&quot;라며 어린 왕자가 말했다. &quot;안녕... | . 23 23장 r n r n &quot;안녕하세요.&quot;라며 어린 왕자가 말했다. &quot;안녕... | . 24 24장 r n r n 비행기 고장으로 사막에 떨어진지도 이제 여덟째 ... | . 25 25장 r n r n &quot;사람들은,&quot;라며 어린 왕자가 말했다. &quot;서둘러... | . 26 26장 r n r n 그 우물 가 옆엔 무너진 돌담 하나가 있었다. ... | . 27 27장 r n r n 물론 지금은 6년이 지난 얘기다... 난 아직 ... | . counts = final.applymap(lambda x: np.char.count(x, &quot;어린 왕자&quot;)) counts . chapters . 0 0 | . 1 5 | . 2 6 | . 3 7 | . 4 10 | . 5 2 | . 6 5 | . 7 14 | . 8 8 | . 9 24 | . 10 10 | . 11 6 | . 12 11 | . 13 12 | . 14 14 | . 15 0 | . 16 13 | . 17 4 | . 18 7 | . 19 8 | . 20 1 | . 21 23 | . 22 6 | . 23 3 | . 24 12 | . 25 15 | . 26 20 | . 27 12 | . counts = final.applymap(lambda x: np.char.count(x, &quot;여우&quot;)) counts.plot() . &lt;AxesSubplot:&gt; . &#52309;&#53552;2 &#49892;&#49845; . `hstudent.csv&#39;는 20명의 고등학생 성별, 학년, 키(cm), 몸무게(kg)를 조사한 자료이다. 체질량지수는 몸무게(kg)를 키의 제곱(m)으로 나눈 값입니다. 5번 학생의 체질량지수는? | 10번 학생의 체질량지수는? | 학생의 키와 몸무게를 각각 height 와 weight 에 저장하고, height 와 weight 를 사용하여 체질량지수 계산 5번 과 10번 학생 각각에 대하여 계산한 후 bmi5와 bmi10에 저장 | bmi5 와 bmi10 의 크기 비교 결과 print 함수를 사용하여 보여주기 1번부터 5번까지의 학생 키를 원소로 가지는 리스트 변수 height1_5 생성 | 1번부터 3번까지 학생의 키 추출 | . | 나는 전북대학교 학과 이름 입니다. (예, 나는 전북대학교 통계학과 최혜미입니다) 위 문자열을 값으로 가지는 변수 name_dept 를 생성 변수 name_dept 에서 전북대학교 추출 | &#45813; . dset = pd.read_csv(&quot;hstudent.csv&quot;) . dset[&quot;height_m&quot;] = dset[&quot;height&quot;]/100 . print(dset) . gender grade height weight height_m 0 1 3 183 82 1.83 1 2 1 168 52 1.68 2 2 1 160 48 1.60 3 2 2 160 50 1.60 4 1 1 160 79 1.60 5 1 2 180 73 1.80 6 2 2 183 60 1.83 7 1 1 170 66 1.70 8 1 3 170 74 1.70 9 1 3 185 57 1.85 10 1 2 165 54 1.65 11 2 1 170 50 1.70 12 2 1 152 60 1.52 13 2 3 173 63 1.73 14 1 1 145 57 1.45 15 1 3 163 77 1.63 16 2 2 178 50 1.78 17 2 2 163 57 1.63 18 2 2 168 54 1.68 19 2 3 170 57 1.70 . dset.iloc[4,4] . 1.6 . 체질량지수는 몸무게(kg)를 키의 제곱(m)으로 나눈 값입니다. 5번 학생의 체질량지수는? . 10번 학생의 체질량지수는? | 학생의 키와 몸무게를 각각 height 와 weight 에 저장하고, height 와 weight 를 사용하여 체질량지수 계산 5번 과 10번 학생 각각에 대하여 계산한 후 bmi5와 bmi10에 저장 | bmi5 와 bmi10 의 크기 비교 결과 print 함수를 사용하여 보여주기 | 1번부터 5번까지의 학생 키를 원소로 가지는 리스트 변수 height1_5 생성 | 1번부터 3번까지 학생의 키 추출 | . dset[&quot;weight&quot;][4]/dset[&quot;height_m&quot;][4]**2 #5번 학생의 체질량 지수 . 30.859374999999993 . dset[&quot;weight&quot;][9]/dset[&quot;height_m&quot;][9]**2 . 16.654492330168004 . height = dset[&quot;height&quot;]/100 weight = dset[&quot;weight&quot;] . bmi5 = weight[4]/height[4]**2 bmi10 = weight[9]/height[9]**2 print(bmi5, bmi10) . 30.859374999999993 16.654492330168004 . height1_5 = height[0:5] . height1_5[0:3] . 0 1.83 1 1.68 2 1.60 Name: height, dtype: float64 . name_dept = &quot;나는 전북대학교 학과 이름 입니다&quot; #변수 name_dept 를 생성 name_dept[3:8] #변수 name_dept 에서 전북대학교 추출 . &#39;전북대학교&#39; . &#52309;&#53552; 3 . 부동소수점 : 17번째 자리를 아무리 더해도 소수점 16번째까지 출력 -&gt; 17번째자리부터 부동소수점 파이썬은 소수점 16자리까지 인식한다. 17번째부터는 인식 x . 1/3 == (1/3 + 0.0000000000000001) #소수점 16번째 자리 더하기 . False . 1/3 == (1/3 + 0.00000000000000001) #소수점 17번째 자리 더하기 . True . text_4 = r&#39;C: some name&#39; print(text_4) . C: some name . &#49892;&#49845; . 본인의 단대, 학과, 학번, 이름(영문)을 각각 문자열로 정의하여라. 정의된 문자열을 하나로 결합하여라. | 위에서 정의된 본인의 이름을 모두 대문자로 바꾸어라. | 위에서 결합된 문자열에서 본인의 이름을 국문으로 바꾸어라. | 본인의 생년월일을 다음과 같은 형식으로 표기하는 문자열을 정의하여라. 1990/02/16 | 생년월일에서 년에 해당하는 정보만을 추출하여라. | 생년월일을 년, 월, 일 새 부분으로 나누어라. | &#45813; . school = &quot;인문대&quot; major = &quot;스페인중남미학과&quot; number = &quot;201821502&quot; name = &quot;hyeji&quot; me = school + &quot; &quot; + major +&quot; &quot; + number + &quot; &quot; + name me . &#39;인문대 스페인중남미학과 201821502 hyeji&#39; . name.upper() . &#39;HYEJI&#39; . me.replace(&quot;hyeji&quot;, &quot;혜지&quot;) . &#39;인문대 스페인중남미학과 201821502 혜지&#39; . birth = &quot;2114/3/23&quot; birth[:4] birth.split(&quot;/&quot;) #f1, f2, f3 = birth.split(sep=&quot;/&quot;) . [&#39;2114&#39;, &#39;3&#39;, &#39;23&#39;] . &#52309;&#53552;3 &#47928;&#51228; . 다음과 같은 코드를 먼저 실행하고 물음에 답하여라 . A = np.array([1, 4, 2, 5, 3]) . 1) A의 1, 3, 5 번째 원소를 추출하여라 2) A의 마지막 원소만 제외한 나머지로 이루어진 1차원 배열을 추출하여라 3) 5에서 1씩 감소하는 길이가 5인 1차원 배열을 만들고 B라 명명하여라 4) A와 B를 순서대로 연결하는 1차원 배열 C를 만들어라(concatenate([x,y])이용) 5) 위에서 만들어진 C로부터 A가 첫번째 행, B를 두번째 행이 되도록 2차원 배열(행렬) D를 정의 하여라 6) D의 첫 두번째 행과 첫 두번째 열로 이루어진 부분행렬을 추출하여라 7) D의 세 번째 열로만 이루어진 배열을 추출하여라. 단, 1차원 배열이 아니라 2차원 배열의 속성을 그대로 가지도록 하여라 . &#45813; . import numpy as np import pandas as pd . A = np.array([1,4,2,5,3]) #1,3,5번째 원소를 출력하여라 . A[[0,2,4]] # A[0:5:2] . array([1, 2, 3]) . A[0:4] . array([1, 4, 2, 5]) . B = np.arange(5,0,-1) B . array([5, 4, 3, 2, 1]) . C = np.concatenate([A,B]) C . array([1, 4, 2, 5, 3, 5, 4, 3, 2, 1]) . D = C.reshape(2, 5) . D[:2,:2] #D의 첫 두번째 행과 첫 두번째 열로 이루어진 부분행렬을 추출하여라 . array([[1, 4], [5, 4]]) . D[:,2].reshape(2,1) . array([[2], [3]]) . &#52309;&#53552;4/ &#45936;&#51060;&#53552;&#54532;&#47112;&#51076; . import pandas as pd import numpy as np . &#47928;&#51228; . 데이터 프레임 만들기 | 최대값 구하기 | 평균 구하기 | 중간고사에서 80점이상인 데이털르 새로운 데이터 프레임으로 저장 | 리테이크별로 그룹바이 한 후 중간고사를 선택해 평균구하기 | retake를 한 중간고사 성적의 평균 | retake 하지 않은 중간고사 성적의 평균 | 3번째행과 2번째열로 둘러싼 데이터 프레임 | 2,3열, 2행 데이터 프레임 뽑기 | 영철의 중간고사 성적 뽑기 | df = pd.DataFrame({&#39;midterm&#39; : [74,82,67,89,92] , &#39;final&#39; : [91,77,88,78,86], &#39;hw&#39; : [8,9,7,8,10], &#39;retake&#39; : [True,False,False,True,False]}, index=[&#39;영수&#39;,&#39;영희&#39;,&#39;정숙&#39;,&#39;영철&#39;,&#39;광수&#39;]) df . midterm final hw retake . 영수 74 | 91 | 8 | True | . 영희 82 | 77 | 9 | False | . 정숙 67 | 88 | 7 | False | . 영철 89 | 78 | 8 | True | . 광수 92 | 86 | 10 | False | . &#45813; . df.max() . midterm 92 final 91 hw 10 retake True dtype: object . df.mean() . midterm 80.8 final 84.0 hw 8.4 retake 0.4 dtype: float64 . df1=df[df[&quot;midterm&quot;] &gt;= 80] df1 . midterm final hw retake . 영희 82 | 77 | 9 | False | . 영철 89 | 78 | 8 | True | . 광수 92 | 86 | 10 | False | . df.groupby(&quot;retake&quot;)[&quot;midterm&quot;].mean() #리테이크별로 그룹바이 한 후 중간고사를 선택해 평균구하기 . retake False 80.333333 True 81.500000 Name: midterm, dtype: float64 . df.midterm[df.retake == True].mean() #retake를 한 중간고사 성적의 평균 # 같은 열에서 조건식을 걸어주고 싶으니까 .Retake 사용한 것 . 81.5 . df.midterm[df.retake == False].mean() #행과 열이 아닌 열과 열에서 조건을 주고싶음! . 80.33333333333333 . df.iloc[:3,:2] . midterm final . 영수 74 | 91 | . 영희 82 | 77 | . 정숙 67 | 88 | . df.iloc[1:3,2] . 영희 9 정숙 7 Name: hw, dtype: int64 . df.loc[&quot;영철&quot;, &quot;midterm&quot;] . 89 . &#47928;&#51228; . 데이터 불러오기 | 지역별로 묶고 &quot;year&quot;열 없애서 house1으로 저장 | 전라북도 행 출력 | h2에 리셋한 h1을 저장하고/ 지역이 전라북도인 시리즈를 뽑는다 | 원 데이터에 집 토탈을 구해서 새로운 열을 만든다. | 연도별 그룹으로 묶고 더한 값을 h3에 저장한다. | h3 데이터에서 1인 가구와 2인가구의 집 백분율을 구한다. | h3을 reset_index 하고 라인그래프를 그린다. | 데이터 중 서울 지역 집 시간에 따른 1인가구 2인가구 백분율 라인플랏 그리기 | 전라북도 라인플랏 | import pandas as pd import matplotlib.pyplot as plt house = pd.read_csv(&quot;https://ilovedata.github.io/teaching/bigdata2/data/house_final.csv&quot;, encoding=&quot;utf-8&quot;) house.head() . year region p1 p2 p3 p4 p5 p6 p7plus . 0 2015 | 서울특별시 | 1115744 | 930467 | 817440 | 701945 | 169436 | 38547 | 10911 | . 1 2015 | 부산광역시 | 361749 | 366048 | 296742 | 238031 | 56971 | 12928 | 3431 | . 2 2015 | 대구광역시 | 239517 | 239824 | 208795 | 184258 | 44071 | 9582 | 2481 | . 3 2015 | 인천광역시 | 243678 | 265079 | 245135 | 220538 | 55230 | 12253 | 3504 | . 4 2015 | 광주광역시 | 163577 | 137662 | 115701 | 109612 | 32199 | 6647 | 1759 | . &#45813; . house1 = house.groupby(&quot;region&quot;).mean().drop(columns = &quot;year&quot;) house1.head() . p1 p2 p3 p4 p5 p6 p7plus . region . 강원도 2.055773e+05 | 1.910527e+05 | 1.173895e+05 | 82851.166667 | 23434.166667 | 5673.000000 | 1798.333333 | . 경기도 1.185570e+06 | 1.191405e+06 | 1.067674e+06 | 960720.166667 | 234949.833333 | 50353.500000 | 14278.500000 | . 경상남도 3.773923e+05 | 3.685377e+05 | 2.696208e+05 | 216805.833333 | 53716.166667 | 11199.333333 | 3189.500000 | . 경상북도 3.514700e+05 | 3.385347e+05 | 2.067188e+05 | 146853.833333 | 37757.333333 | 8697.666667 | 2700.833333 | . 광주광역시 1.751827e+05 | 1.490100e+05 | 1.165850e+05 | 103157.666667 | 28710.666667 | 5462.833333 | 1423.833333 | . house1[house1.index==&quot;전라북도&quot;] . p1 p2 p3 p4 p5 p6 p7plus . region . 전라북도 231692.166667 | 218931.5 | 136002.833333 | 103485.166667 | 32534.0 | 7726.333333 | 2581.666667 | . h2 = h1.reset_index() h2[h2.region == &quot;전라북도&quot;] . region p1 p2 p3 p4 p5 p6 p7plus . 13 전라북도 | 231692.166667 | 218931.5 | 136002.833333 | 103485.166667 | 32534.0 | 7726.333333 | 2581.666667 | . house[&quot;total&quot;] = house[[&quot;p1&quot;,&quot;p2&quot;,&quot;p3&quot;,&quot;p4&quot;,&quot;p5&quot;,&quot;p6&quot;,&quot;p7plus&quot;]].sum(axis=1) house.head() . year region p1 p2 p3 p4 p5 p6 p7plus total . 0 2015 | 서울특별시 | 1115744 | 930467 | 817440 | 701945 | 169436 | 38547 | 10911 | 3784490 | . 1 2015 | 부산광역시 | 361749 | 366048 | 296742 | 238031 | 56971 | 12928 | 3431 | 1335900 | . 2 2015 | 대구광역시 | 239517 | 239824 | 208795 | 184258 | 44071 | 9582 | 2481 | 928528 | . 3 2015 | 인천광역시 | 243678 | 265079 | 245135 | 220538 | 55230 | 12253 | 3504 | 1045417 | . 4 2015 | 광주광역시 | 163577 | 137662 | 115701 | 109612 | 32199 | 6647 | 1759 | 567157 | . h3 = house.groupby(&quot;year&quot;).sum() #6. 연도별 그룹으로 묶고 더한 값을 h3에 저장한다. h3 . p1 p2 p3 p4 p5 p6 p7plus total . year . 2015 5203440 | 4993818 | 4100979 | 3588931 | 940413 | 217474 | 65975 | 19111030 | . 2016 5397615 | 5067166 | 4151701 | 3551410 | 924373 | 211475 | 63956 | 19367696 | . 2017 5618677 | 5260332 | 4178641 | 3473897 | 886479 | 197517 | 58332 | 19673875 | . 2018 5848594 | 5445691 | 4203792 | 3396320 | 849167 | 182886 | 52738 | 19979188 | . 2019 6147516 | 5663330 | 4217736 | 3300114 | 801048 | 166866 | 46578 | 20343188 | . 2020 6643354 | 5864525 | 4200629 | 3271315 | 761417 | 147172 | 38298 | 20926710 | . house[&quot;p1p2_percent&quot;] = house[&quot;p1&quot;] + house[&quot;p2&quot;] / house[&quot;total&quot;] *100 #7. 데이터에서 1인 가구와 2인가구의 집 house[&quot;p1p2_percent&quot;]을 구한다. . h3.reset_index().plot.line(x=&quot;year&quot;, y=&#39;p1p2_percent&#39;) #8. h3을 reset_index 하고 라인그래프를 그린다. . &lt;AxesSubplot:xlabel=&#39;year&#39;&gt; . house[house.region == &quot;서울특별시&quot;].plot.line(x=&quot;year&quot;, y=&#39;p1p2_percent&#39;) . &lt;AxesSubplot:xlabel=&#39;year&#39;&gt; . house[house.region == &quot;전라북도&quot;].plot.line(x=&quot;year&quot;, y=&#39;p1p2_percent&#39;) . &lt;AxesSubplot:xlabel=&#39;year&#39;&gt; . &#52309;&#53552; 5 . import matplotlib.pyplot as plt from matplotlib import rc %matplotlib inline plt.rc(&#39;font&#39;, family=&#39;NanumBarunGothic&#39;) # clolab 에서 한글 사용 plt.rcParams[&#39;axes.unicode_minus&#39;] = False plt.rcParams[&quot;figure.figsize&quot;] = (8,8) # 그림 크기 조정 import pandas as pd . import numpy as np import pandas as pd . &#47928;&#51228; . 수의 값이 0.5 보다 작으면 앞면 을 출력하고, 아니면(0.5 보다 크면) 뒷면을 출력하는 조건문 . &#45813; . x = np.random.rand(1) #랜덤으로 난 수 하나 출력하는 코드 print(x) if x &lt; 0.5 : print(&quot;앞면&quot;) else : print(&quot;뒷면&quot;) . [0.48103662] 앞면 . . for i in np.arange(10) : print(i) . 0 1 2 3 4 5 6 7 8 9 . mynumbers = np.arange(1,11) ## 1부터 10까지 저장된 벡터 - 끝나는 숫자기 11인것에 유의하다. mysum = 0 for i in mynumbers : mysum = mysum + i mysum . 55 . for i in [ &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;] : print(i) . A B C D . for i in np.arange(5) : for j in np.arange(3) : print(i,j) . 0 0 0 1 0 2 1 0 1 1 1 2 2 0 2 1 2 2 3 0 3 1 3 2 4 0 4 1 4 2 . 이제 위에서 동전을 던지는 코드를 10회 반복해 보자. 여러분이 아래 명령문 for i in np.arange(10) 에서 10을 다른 숫자로 바꾸면, 예를 들어 100으로 바꾸면 100번 동전을 던진 결과가 출력될 것이다. . for i in np.arange(10) : x = np.random.rand(1) print(x) if x &lt; 0.5 : print(&quot;앞면&quot;) else : print(&quot;뒷면&quot;) . [0.34776953] 앞면 [0.64320035] 뒷면 [0.12384762] 앞면 [0.11047998] 앞면 [0.2917453] 앞면 [0.11990323] 앞면 [0.87792724] 뒷면 [0.09482876] 앞면 [0.7975045] 뒷면 [0.93272364] 뒷면 . N = 1000 count_head = 0 for i in np.arange(N) : x = np.random.rand(1) if x &lt; 0.5 : count_head = count_head + 1 count_head . 480 . &#47928;&#51228; . 나는 1,000,000원 을 가지고 있다. . 내가 구입한 금융상품은 KOSPI 주식 중에 하루마다 주식 종목을 임의로 선택해서 주식 가격이 전날에 비해 오르면 10,000원을 벌고, 내려가면 10,000원을 잃는다. . 임의로 선택한 주식 종목이 전날에 비해 올라갈 확률은 0.55 로 볼 수 있다. 난 1년 내로 얼마나 벌 수 있을까? . &#45813; . My_money = 1000000 Number_of_days = 365 for i in np.arange(Number_of_days) : x = np.random.rand(1) if x &lt; 0.55 : My_money = My_money + 10000 else : My_money = My_money - 10000 My_money . 1410000 . &#47928;&#51228; . 더 나아가서 여러분과 같이 백만원을 가지고 이 투자상품을 산 사람이 1000 명이라고 하자. 투자한 사람들의 1년 후 잔고는 어떤 분포를 가질까? . 먼저 다음과 같이 초기 변수를 정의하자. . 초기 투자 금액: My_money 투자자의 수: Number_of_people 투자 일수: Number_of_days 임의로 선택한 주식 종목이 전날보다 오를 확률 : P = 0.05 . &#45813; . Number_of_people = 1000 My_money = 1000000 Number_of_days = 365 P = 0.05 . People_money = np.repeat(My_money, Number_of_people) People_money[0:10] . array([1000000, 1000000, 1000000, 1000000, 1000000, 1000000, 1000000, 1000000, 1000000, 1000000]) . 먼저 투자일 i 를 선택하고, 다음 투자자 j 마다 임의로 선택한 주식의 가격에 대한 결과를 투자 금액 People_money[j]에 반영하였다. . 1차 반복에서 투자일 선택: for i in np.arange(Number_of_days) . 2차 반복에서 투자자 선택: for j in np.arange(Number_of_people) . 임의로 선택한 주식의 결과 x 에 따라서 j 번째 투자자의 금액 업데이트 . for i in np.arange(Number_of_days) : for j in np.arange(Number_of_people) : x = np.random.rand(1) if x &lt; P : People_money[j] = People_money[j] + 10000 else : People_money[j] = People_money[j] - 10000 . df = pd.DataFrame({ &#39;money&#39;: People_money}) df.head(10) . money . 0 -2250000 | . 1 -2210000 | . 2 -2150000 | . 3 -2330000 | . 4 -2270000 | . 5 -2130000 | . 6 -2330000 | . 7 -2230000 | . 8 -2330000 | . 9 -2350000 | . df[&#39;money&#39;].plot.hist(bins=20) . &lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt; . df[df[&quot;money&quot;] &lt; My_money ].count() . money 10000 dtype: int64 .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/26/%EA%B0%9C%EB%A1%A0%EC%A4%91%EA%B0%84.html",
            "relUrl": "/python/2022/10/26/%EA%B0%9C%EB%A1%A0%EC%A4%91%EA%B0%84.html",
            "date": " • Oct 26, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "데이터 시각화 7",
            "content": "import numpy as np import matplotlib.pyplot as plt . lambda . 예제1 : 람다 표현식 자체가 하나의 오브젝트 | . (lambda x : x + 1)(300) #이름도 안 붙이고 사용하고 싶을 때 사용 # lambda 가 실행되는 순간 메모리상에 함수 오브젝트가 저장됨 . 301 . (lambda x : (x-2)**2)(2) . 0 . &quot;lambda x: (x-2)**2&quot; 는 lambda(x)=(x-2)^2lambda(x)=(x−2)^2의 느낌으로 기억하면 쉬움 | . (lambda x: (x-2)**2)(4) # 입력5 -&gt; 출력 (4-2)^2 =4 . 4 . (lambda x: (x-2)**2)(6) # 입력6 -&gt; 출력 (6-2)^2 =16 . 16 . (lambda x: (x-2)**2)(-2) # 입력-2 -&gt; 출력 (-2-2)^2 =16 . 16 . 예제2: 람다표현식에 이름을 줄 수 있음. | . f = lambda x: (x-2)**2 . f(2),f(4),f(6),f(-2) . (0, 4, 16, 16) . 위의 코드는 아래와 같다. . def f(x): return (x-2)**2 f(2),f(4),f(6),f(-2) . (0, 4, 16, 16) . 예제3: 조건부 출력 | . f = lambda x,y: x if x&gt;y else y # x,y가 입력 -&gt; x&gt;y 일때만 x를 리턴하고 그렇지않으면 y를 리턴 = 큰값을 리턴하라는 소리임 . f(1,20) . 20 . 예제4: 람다표현식들의 리스트 | . fl = [lambda x: x, lambda x: x**2, lambda x: x**3] #한 번에 묶어서 리스트로 만들 수 있음 . fl[0](100) #렝이 있으면 원소에 접근 가능[], 그리고 거기에다가 숫자입력해서 쓸 수 있음 . 100 . for f in fl: print(f(2)) . 2 4 8 . for s in [&#39;a&#39;, lambda x : x, &#39;c&#39;]: print(s) . a &lt;function &lt;lambda&gt; at 0x7f9142898b80&gt; c . x = np.linspace(-1,1,100) for f in fl: plt.plot(x,f(x),&#39;--&#39;) . 예제5: 람다표현식들의 딕셔너리 | . fd = {&#39;f1&#39;:lambda x: x, &#39;f2&#39;:lambda x: x**2, &#39;f3&#39;:lambda x: x**3} fd . {&#39;f1&#39;: &lt;function __main__.&lt;lambda&gt;(x)&gt;, &#39;f2&#39;: &lt;function __main__.&lt;lambda&gt;(x)&gt;, &#39;f3&#39;: &lt;function __main__.&lt;lambda&gt;(x)&gt;} . fd[k] . &lt;function __main__.&lt;lambda&gt;(x)&gt; . for k in fd: plt.plot(x,fd[k](x),&#39;--&#39;) #fd[k] : 함수 오브젝트 . 예제6: 람다표현식을 리턴하는 함수 (함수를 리턴하는 함수) | . (예비학습) 함수 g(x)g(x)가 정의되어 있을때 $ frac{d}{dx}g(x)$의 값을 계산해보자(도함수) . g = lambda x : x**2 . g(3) . 9 . gg = lambda x : (g(x+0.001)-g(x))/0.001 . gg(4) . 8.0010000000037 . (목표) 도함수를 구해주는 derivate 함수를 정의하자. 이 함수는 임의의 함수 g를 입력으로 받으면, g의 도함수(gg)가 리턴되는 기능을 가진다. . def derivate(g): return lambda x: (g(x+0.001)-g(x))/0.001 . (사용1) . g = lambda x: np.sin(x) . gg =derivate(g) . x = np.linspace(0,6.28, 1000) . plt.plot(x,g(x)) plt.plot(x,gg(x)) . [&lt;matplotlib.lines.Line2D at 0x7f916195cd90&gt;] . (사용2) . g0 = lambda x: (1/6)*x**3 g1 = derivate(g0) # (1/2)x^2 g2 = derivate(g1) # x . x = np.linspace(-1,1,100) plt.plot(x,g0(x),&#39;--&#39;,label=r&#39;$g_0(x)= frac{1}{6}x^3$&#39;) plt.plot(x,g1(x),&#39;--&#39;,label=r&#39;$g_1(x)= frac{1}{2}x^2$&#39;) plt.plot(x,g2(x),&#39;--&#39;,label=r&#39;$g_2(x)=x$&#39;) plt.legend(fontsize=15); . 예제7 | . derivate = lambda g: lambda x: (g(x+0.001)-g(x))/0.001 . &#47605; . x=[1,2,3] f = lambda x: x+1 y = list(map(f,x)) . (다른구현1) . list(map(lambda x: x+1,[1,2,3])) . [2, 3, 4] . (다른구현2) . f = lambda x: x+1 [f(xi) for xi in [1,2,3]] . [2, 3, 4] . (다른구현3) . [(lambda x: x+1)(xi) for xi in [1,2,3]] . [2, 3, 4] . 예제2: 문자열을 입력으로 받고 대문자이면 True, 소문자이면 False | . x= list(&#39;ABCabc&#39;) # x = [&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] f = lambda s: s.isupper() y = list(map(f,x)) . 예제3 - 두개의 입력을 받는 함수는 맵을 이용하는 것이 리스트 컴프리헨션보가 조금 편한 것 같다. | . list(map(lambda x,y: x+y, [1,2,3],[-1,-2,-3])) . [0, 0, 0] . (다른구현)-- 리스트컴프리헨션 . f = lambda x,y: x+y [f(x,y) for x,y in zip([1,2,3],[-1,-2,-3])] . [0, 0, 0] . 예제4 : 맵은 &quot;하나의 함수에 다양한 입력&quot;을 적용하는 경우에만 사용가능, 리스트 컴프리헨션은 &quot;다양한 함수에 다양한 입력&quot; 지원 | . flst = [lambda x: x+1, lambda x: x+2, lambda x:x+3] . 맵으로 구현 시도 . list(map(flst,[-1,-2,-3])) -&gt; 실패 . Input In [18] list(map(flst,[-1,-2,-3])) -&gt; 실패 ^ SyntaxError: invalid syntax . 리스트컴프리헨션으로 구현시도 -&gt; 성공 . [f(x) for f,x in zip(flst,[-1,-2,-3])] . [0, 0, 0] . 종합: map과 리스트컴프리헨션과 비교 | . map은 for문을 위한 i등의 인덱스를 쓰지 않지만 리스트컴프리헨션은 필요함 . map은 좀더 리스트컴프리헨션보다 제약적으로 사용할 수 밖에 없음. . &#51064;&#45937;&#49905; 1&#45800;&#44228;-- &#51064;&#45937;&#49905;&#51032; 4&#44032;&#51648; &#52968;&#49481; . &#45936;&#51060;&#53552;&#54532;&#47112;&#51076; . import pandas as pd . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/dv2022.csv&#39;) df . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 3 55 | 35 | 35 | 5 | . 4 80 | 60 | 55 | 70 | . ... ... | ... | ... | ... | . 195 55 | 70 | 40 | 95 | . 196 65 | 85 | 25 | 85 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 199 50 | 95 | 45 | 85 | . 200 rows × 4 columns . 앞으로는 위와 같은 df형태를 가정할 것이다. 즉 column의 이름은 문자열, row의 이름은 0부터 시작하는 정수로 가정한다. . | 아래와 같은 형태는 일단 생각하지 않는다. . | . pd.DataFrame({&#39;att&#39;:[60,65,80,90],&#39;rep&#39;:[50,100,90,100]},index=[&#39;규빈&#39;,&#39;영미&#39;,&#39;성준&#39;,&#39;혜미&#39;]) . att rep . 규빈 60 | 50 | . 영미 65 | 100 | . 성준 80 | 90 | . 혜미 90 | 100 | . df&#51032; 4&#44032;&#51648; &#52968;&#49481; . 원소에 접근하는 4가지 방법: ., [], .iloc[], .loc[] | . &#52968;&#49481;1: &#53364;&#47000;&#49828;&#45712;&#45196; . 컨셉1: df는 인스턴스이다. 그리고 df.att, df.rep,df.mid, df.fin 와 같이 col이름에 대응하는 속성이 있다 | . df.head() . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 3 55 | 35 | 35 | 5 | . 4 80 | 60 | 55 | 70 | . df.rep #언제유용? 열의 이름을 대충 알고 있을 경우 자동완성으로 쉽게 선택가능 . 0 45 1 30 2 85 3 35 4 60 .. 195 70 196 85 197 85 198 65 199 95 Name: rep, Length: 200, dtype: int64 . &#52968;&#49481;2: &#46357;&#49492;&#45320;&#47532; +&#945; &#45712;&#45196; . 컨셉2: df는 컬럼이름이 key, 컬럼의데이터가 value가 되는 dictionary로 이해할 수 있다. 즉 아래의 dct와 같은 딕셔너리로 이해할 수 있다. | . dct = dict(df) . dct.keys(), df.keys() . (dict_keys([&#39;att&#39;, &#39;rep&#39;, &#39;mid&#39;, &#39;fin&#39;]), Index([&#39;att&#39;, &#39;rep&#39;, &#39;mid&#39;, &#39;fin&#39;], dtype=&#39;object&#39;)) . col indexing | 예시1: dct가 가능하면 df도 가능하다. | . df[&#39;att&#39;] #dct[&#39;att&#39;] . 0 65 1 95 2 65 3 55 4 80 .. 195 55 196 65 197 85 198 80 199 50 Name: att, Length: 200, dtype: int64 . 예시2: dct가 가능하면 df도 가능하다. (2) | . df.get(&#39;att&#39;) . 0 65 1 95 2 65 3 55 4 80 .. 195 55 196 65 197 85 198 80 199 50 Name: att, Length: 200, dtype: int64 . 예시3: dct에서 불가능하지만 df에서 가능한것도 있다. | . df.get([&#39;att&#39;, &#39;rep&#39;]) . att rep . 0 65 | 45 | . 1 95 | 30 | . 2 65 | 85 | . 3 55 | 35 | . 4 80 | 60 | . ... ... | ... | . 195 55 | 70 | . 196 65 | 85 | . 197 85 | 85 | . 198 80 | 65 | . 199 50 | 95 | . 200 rows × 2 columns . df.get([&#39;att&#39;,&#39;rep&#39;]) . att rep . 0 65 | 45 | . 1 95 | 30 | . 2 65 | 85 | . 3 55 | 35 | . 4 80 | 60 | . ... ... | ... | . 195 55 | 70 | . 196 65 | 85 | . 197 85 | 85 | . 198 80 | 65 | . 199 50 | 95 | . 200 rows × 2 columns . 예시4: dct에서 불가능하지만 df에서 가능한것도 있다. (2) | . dct[[&#39;att&#39;,&#39;rep&#39;]] . TypeError Traceback (most recent call last) Input In [47], in &lt;cell line: 1&gt;() -&gt; 1 dct[[&#39;att&#39;,&#39;rep&#39;]] TypeError: unhashable type: &#39;list&#39; . df[[&#39;att&#39;,&#39;rep&#39;]] . att rep . 0 65 | 45 | . 1 95 | 30 | . 2 65 | 85 | . 3 55 | 35 | . 4 80 | 60 | . ... ... | ... | . 195 55 | 70 | . 196 65 | 85 | . 197 85 | 85 | . 198 80 | 65 | . 199 50 | 95 | . 200 rows × 2 columns . row indexing | 예시5: dct에서 불가능하지만 df에서 가능한것도 있다. (3) | . dct[:5] . TypeError Traceback (most recent call last) Input In [50], in &lt;cell line: 1&gt;() -&gt; 1 dct[:5] TypeError: unhashable type: &#39;slice&#39; . df[:5] . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 3 55 | 35 | 35 | 5 | . 4 80 | 60 | 55 | 70 | . &#52968;&#49481;3: &#45336;&#54028;&#51060;&#45712;&#45196; . 컨셉3: df.iloc은 넘파이에러이처럼 생각가능하다. | . 즉 아래의 arr와 같은 넘파이어레이로 생각가능하다. . import numpy as np . arr = np.array(df) #arr . row indexing | 예시1: 단일레이블 | . arr[0,] #arr[0] . array([65, 45, 0, 10]) . df.iloc[0,] #df.iloc[0] . att 65 rep 45 mid 0 fin 10 Name: 0, dtype: int64 . 예시2: 레이블의 리스트 | . arr[[0,1,2],:] # 처음 3개의 row 선택 arr[[0,1,2],] arr[[0,1,2]] . array([[65, 45, 0, 10], [95, 30, 60, 10], [65, 85, 15, 20]]) . df.iloc[[0,1,2],:] # 처음 3개의 row 선택 df.iloc[[0,1,2],] df.iloc[[0,1,2]] #데이터 프레임.iloc[] . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 예시3: 슬랑이싱 | . arr[0:3,:] # 처음 3개의 row선택, 끝점포함X arr[0:3,] arr[0:3] . array([[65, 45, 0, 10], [95, 30, 60, 10], [65, 85, 15, 20]]) . df.iloc[0:3,:] # 처음 3개의 row선택, 끝점포함X df.iloc[0:3,] df.iloc[0:3] . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . col indexing | 예시1: 단일레이블 | . df.iloc[:,0] # first column # arr[:,0] # first column . 0 65 1 95 2 65 3 55 4 80 .. 195 55 196 65 197 85 198 80 199 50 Name: att, Length: 200, dtype: int64 . 예시2: 레이블의 리스트 | . df.iloc[:,[0,2]] # col1, col3 을 선택 # arr[:,[0,2]] # col1, col3 을 선택 . att mid . 0 65 | 0 | . 1 95 | 60 | . 2 65 | 15 | . 3 55 | 35 | . 4 80 | 55 | . ... ... | ... | . 195 55 | 40 | . 196 65 | 25 | . 197 85 | 100 | . 198 80 | 35 | . 199 50 | 45 | . 200 rows × 2 columns . 예시3: 슬랑이싱 | . df.iloc[:,0:3] # 처음 3개의 col선택, 끝점포함X #arr[:,0:3] . att rep mid . 0 65 | 45 | 0 | . 1 95 | 30 | 60 | . 2 65 | 85 | 15 | . 3 55 | 35 | 35 | . 4 80 | 60 | 55 | . ... ... | ... | ... | . 195 55 | 70 | 40 | . 196 65 | 85 | 25 | . 197 85 | 85 | 100 | . 198 80 | 65 | 35 | . 199 50 | 95 | 45 | . 200 rows × 3 columns . df.iloc[::2,0:3] . att rep mid . 0 65 | 45 | 0 | . 2 65 | 85 | 15 | . 4 80 | 60 | 55 | . 6 65 | 70 | 60 | . 8 95 | 55 | 65 | . ... ... | ... | ... | . 190 95 | 35 | 40 | . 192 100 | 40 | 80 | . 194 65 | 40 | 65 | . 196 65 | 85 | 25 | . 198 80 | 65 | 35 | . 100 rows × 3 columns . &#52968;&#49481; 4: &#45936;&#51060;&#53552;&#54532;&#47112;&#51076; &#45712;&#45196; . 컨셉4: df.loc은 새로운 느낌.. (R에 익숙하면 df.loc이 dataframe 혹은 티블느낌이라고 보시면 됩니다) - 코랩에서만 사용 가능 | . col 이름을 알아야하는 부담감 | . . : 앞글자만 대충 알아도 자동완성 가능 . []: 정확한 col 이름을 알아야 함 . .loc: 보통 정확한 col 이름을 알아야 하지만 슬라이싱 이용시 양 끝의 컬럼이름만 알면 무방 . .iloc: 정확한 col 이름을 몰라도 번호로 인덱싱 가능 . 자주하는 실수 | . df[&#39;att&#39;] # 가능 # df.loc[&#39;att&#39;] # 불가능 df.loc[:,&#39;att&#39;] # 가능 . 0 65 1 95 2 65 3 55 4 80 .. 195 55 196 65 197 85 198 80 199 50 Name: att, Length: 200, dtype: int64 . df: &#51064;&#45937;&#49905; 2&#45800;&#44228;-- &#54596;&#53552;&#47553;(&#53945;&#51221;&#51312;&#44148;&#50640; &#47582;&#45716; row&#47484; &#49440;&#53469;) . att &gt; 90 and rep &lt; 50 . 방법1: .query()를 이용 | . #df.rep #(df.att &gt; 90) &amp; (df.rep &lt; 50) #df[(df.att &gt; 90) &amp; (df.rep &lt; 50)] #df.query(&#39;(att&gt;90)&amp;(rep&lt;50)&#39;) #df.query(&#39;att&gt;90 &amp; rep&lt;50&#39;) df.query(&#39;att&gt;90 and rep&lt;50&#39;) . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 방법 2: [], .iloc, .loc | . df[(df.att &gt; 90)&amp;(df.rep &lt; 50)] df.loc[(df.att &gt; 90)&amp;(df.rep &lt; 50)] df.iloc[list((df.att &gt; 90)&amp;(df.rep &lt; 50))] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 방법3: [], .iloc, .loc // map, lambda | . df[list(map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep))] # df[map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep)] # 이것은 불가능 #리스트를 한 다음에 df를 취하기 . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . df.iloc[list(map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep))] df.iloc[map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep)] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . df.loc[list(map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep))] df.loc[map(lambda x,y: (x&gt;90)&amp;(y&lt;50), df.att, df.rep)] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 12 95 | 35 | 0 | 25 | . 48 95 | 45 | 35 | 80 | . 56 95 | 25 | 95 | 90 | . 78 95 | 45 | 90 | 35 | . 107 100 | 30 | 60 | 65 | . 112 100 | 35 | 70 | 0 | . 113 95 | 45 | 55 | 65 | . 163 100 | 25 | 10 | 20 | . 174 100 | 40 | 40 | 15 | . 176 100 | 30 | 70 | 70 | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . . [] .iloc .loc . row/단일레이블 | X | X | O | O | . col/단일레이블 | O | O | O | O | . row/레이블리스트 | X | X | O | O | . col/레이블리스트 | X | O | O | O | . row/슬라이싱 | X | O | O | O | . col/슬라이싱 | X | X | O | O | . row/bool,list | X | O | O | O | . row/bool,ser | X | O | X | O | . row/bool,map | X | X | O | O | . att &gt; mean(att) . 방법1: .query()를 이용 | . df.query(&#39;att&gt; att.mean()&#39;) . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns . 방법2: [], .iloc, .loc | . df[df.att &gt; df.att.mean()] df.loc[df.att &gt; df.att.mean()] df.iloc[list(df.att &gt; df.att.mean())] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns . 방법3: [], .iloc, .loc // map, lambda | . df[list(map(lambda x: x&gt;df.att.mean() , df.att))] # df[map(lambda x: x&gt;df.att.mean() , df.att)] # 이것은 불가능 . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns . df.iloc[list(map(lambda x: x&gt;df.att.mean() , df.att))] df.iloc[map(lambda x: x&gt;df.att.mean() , df.att)] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns . df.loc[list(map(lambda x: x&gt;df.att.mean() , df.att))] df.loc[map(lambda x: x&gt;df.att.mean() , df.att)] . att rep mid fin . 1 95 | 30 | 60 | 10 | . 4 80 | 60 | 55 | 70 | . 8 95 | 55 | 65 | 90 | . 9 90 | 25 | 95 | 50 | . 11 95 | 60 | 25 | 55 | . ... ... | ... | ... | ... | . 184 100 | 30 | 30 | 85 | . 190 95 | 35 | 40 | 95 | . 192 100 | 40 | 80 | 80 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 95 rows × 4 columns .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/17/lambda.html",
            "relUrl": "/python/2022/10/17/lambda.html",
            "date": " • Oct 17, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "10월 14일 과제",
            "content": "다음과 같은 데이터프레임을 불러온 뒤 물음에 답하라 . import pandas as pd . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/dv2022.csv&#39;) df . att rep mid fin . 0 65 | 45 | 0 | 10 | . 1 95 | 30 | 60 | 10 | . 2 65 | 85 | 15 | 20 | . 3 55 | 35 | 35 | 5 | . 4 80 | 60 | 55 | 70 | . ... ... | ... | ... | ... | . 195 55 | 70 | 40 | 95 | . 196 65 | 85 | 25 | 85 | . 197 85 | 85 | 100 | 10 | . 198 80 | 65 | 35 | 60 | . 199 50 | 95 | 45 | 85 | . 200 rows × 4 columns . (1) 기말고사 성적이 중간고사 성적보다 향상된 학생들을 출력하라. 즉 mid &lt; fin 인 학생들을 출력하라. (다양한 방법으로 연습할 것, 제출은 한 가지 방법으로 구현해도 감점없음) . df.query(&#39;mid&lt;fin&#39;) . att rep mid fin . 0 65 | 45 | 0 | 10 | . 2 65 | 85 | 15 | 20 | . 4 80 | 60 | 55 | 70 | . 5 75 | 40 | 75 | 85 | . 6 65 | 70 | 60 | 75 | . ... ... | ... | ... | ... | . 194 65 | 40 | 65 | 70 | . 195 55 | 70 | 40 | 95 | . 196 65 | 85 | 25 | 85 | . 198 80 | 65 | 35 | 60 | . 199 50 | 95 | 45 | 85 | . 93 rows × 4 columns . (2) 기말고사 성적이 중간고사 성적보다 향상된 학생들의 출석과 레포트 점수를 출력하라. . df[(df.mid &lt; df.fin)].iloc[:,0:2] . att rep . 0 65 | 45 | . 2 65 | 85 | . 4 80 | 60 | . 5 75 | 40 | . 6 65 | 70 | . ... ... | ... | . 194 65 | 40 | . 195 55 | 70 | . 196 65 | 85 | . 198 80 | 65 | . 199 50 | 95 | . 93 rows × 2 columns .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/14/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%EC%88%99%EC%A0%9C.html",
            "relUrl": "/python/2022/10/14/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%EC%88%99%EC%A0%9C.html",
            "date": " • Oct 14, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "10월 12일 숙제",
            "content": "아래와 같이 0~9까지 포함된 리스트를 만들어라 . x=list(range(10)) x . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . 아래와 동일한 기능을 수행하는 함수를 lambda expression으로 정의하라. . def f(xi): return &#39;짝&#39; if (xi % 2)==0 else &#39;홀&#39; . f = lambda x : &quot;짝&quot; if (x%2) == 0 else &quot;홀&quot; . map과 lambda expression 을 이용하여 아래와 같은 결과를 만들어라. (리스트컴프리헨션, for문 사용금지) . y = list(map(f,x)) y . [&#39;짝&#39;, &#39;홀&#39;, &#39;짝&#39;, &#39;홀&#39;, &#39;짝&#39;, &#39;홀&#39;, &#39;짝&#39;, &#39;홀&#39;, &#39;짝&#39;, &#39;홀&#39;] .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/12/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%EC%88%99%EC%A0%9C.html",
            "relUrl": "/python/2022/10/12/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%EC%88%99%EC%A0%9C.html",
            "date": " • Oct 12, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "데이터 시각화 6",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns . x1,y1 = np.random.multivariate_normal([0,0],[[1,0],[0,1]],size=1000).T x2,y2 = np.random.multivariate_normal([2,2],[[1,0.7],[0.7,1]],size=1000).T #이변량정규분포에서 샘플추출 (추출코드를 기억할 필요는 없음) #특징: x1,y1은 무상관으로 x2,y2는 선형관계를 가지도록 추출 . plt.plot(x1,y1,&#39;o&#39;) plt.plot(x2,y2,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fdb59fdc1f0&gt;] . sns.scatterplot(data=None,x=x1,y=y1) #데이터 프레임이 없는 형태 sns.scatterplot(data=None,x=x2,y=y2) . wide df . df1 = data=pd.DataFrame({&#39;x&#39;:x1,&#39;y&#39;:y1}) #딕셔너리를 데이터 프레임에 넣어줌 df1 . x y . 0 -0.649907 | 0.595720 | . 1 1.820380 | 0.198625 | . 2 0.100658 | 0.239103 | . 3 -1.545113 | -0.951085 | . 4 0.064387 | -1.128326 | . ... ... | ... | . 995 0.872503 | -1.004130 | . 996 0.558091 | 0.376766 | . 997 2.590796 | 0.704992 | . 998 0.594856 | 0.697934 | . 999 0.736059 | -0.764732 | . 1000 rows × 2 columns . sns.scatterplot(data=pd.DataFrame({&#39;x&#39;:x1,&#39;y&#39;:y1}),x=&#39;x&#39;,y=&#39;y&#39;) sns.scatterplot(data=pd.DataFrame({&#39;x&#39;:x2,&#39;y&#39;:y2}),x=&#39;x&#39;,y=&#39;y&#39;) #wide하게 만든 df는 별로 경쟁력이 없음 . &lt;AxesSubplot:xlabel=&#39;x&#39;, ylabel=&#39;y&#39;&gt; . sns: long df . (x1, y1) = (1000, 2) (x2, y2) = (1000, 2) . 이것을 길게 이어 붙일거니까 2000에 2가 만들어져야 함 . . x = np.concatenate([x1, x2]) y = np.concatenate([y1, y2]) cat = [&#39;x&#39;]*len(x1) + [&#39;x2&#39;]*len(x2) . np.array(list(x1) + list(x2)) . array([-0.6499075 , 1.82038047, 0.10065827, ..., 1.00445563, 1.62890094, -0.19747213]) . df2 = pd.DataFrame({&#39;x&#39; : x, &#39;y&#39; : y, &#39;cat&#39; : cat }) df2 . x y cat . 0 -0.649907 | 0.595720 | x | . 1 1.820380 | 0.198625 | x | . 2 0.100658 | 0.239103 | x | . 3 -1.545113 | -0.951085 | x | . 4 0.064387 | -1.128326 | x | . ... ... | ... | ... | . 1995 2.394455 | 1.809380 | x2 | . 1996 2.103812 | 2.438614 | x2 | . 1997 1.004456 | 0.858603 | x2 | . 1998 1.628901 | 2.574994 | x2 | . 1999 -0.197472 | 0.755469 | x2 | . 2000 rows × 3 columns . sns.scatterplot(data = df2, x = &#39;x&#39;, y = &#39;y&#39;, hue = &#39;cat&#39; ) . &lt;AxesSubplot:xlabel=&#39;x&#39;, ylabel=&#39;y&#39;&gt; . sns&#51012; &#51060;&#50857;&#54616;&#50668; matplotlib &#50529;&#49884;&#51592;&#50640; &#44536;&#47548; &#44536;&#47532;&#44592;! &#51473;&#50836; . fig,ax = plt.subplots(1,3,figsize=(12,4)) ax[0].plot([1,2,4,3],&#39;--o&#39;) sns.scatterplot(x=x1,y=y1,ax=ax[1]) #ax1에다가 seaborn으로 그림 #세번째 그림 그리기 sns.scatterplot(x=x1,y=y1,ax=ax[2]) sns.scatterplot(x=x2,y=y2,ax=ax[2]) ax[2].plot([1,2,4,3],&#39;-r&#39;,lw=5) . [&lt;matplotlib.lines.Line2D at 0x7fdb4adb5df0&gt;] . import cv2 !wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg #이미지 주소 복사 후 파일 불러오기 img = cv2.imread(&#39;Unequalized_Hawkes_Bay_NZ.jpg&#39;,0) #cv키 임포트 -&gt; 다운받은 파일 img로 저장, 0 : 흑백이미지 생성 !rm Unequalized_Hawkes_Bay_NZ.jpg #저장된 파일이 지워짐 . --2022-10-08 11:06:44-- https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240 Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 110895 (108K) [image/jpeg] Saving to: &#39;Unequalized_Hawkes_Bay_NZ.jpg&#39; Unequalized_Hawkes_ 100%[===================&gt;] 108.30K 505KB/s in 0.2s 2022-10-08 11:06:44 (505 KB/s) - &#39;Unequalized_Hawkes_Bay_NZ.jpg&#39; saved [110895/110895] . img2 = cv2.equalizeHist(img) . img.reshape(-1) #벡터 생성 . array([127, 145, 149, ..., 146, 145, 144], dtype=uint8) . fig,ax = plt.subplots(2,2,figsize=(10,5)) ax[0,0].imshow(img,vmin=0,vmax=255,cmap=&#39;gray&#39;) #cmap :색 지정 sns.histplot(img.reshape(-1),ax=ax[0,1],bins=15,lw=0,kde=True,color=&#39;C1&#39;) #kde : 곡선 만들어줌 ax[0,1].set_xlim(0,255) #x축 범위 바꾸기(mpl) ax[1,0].imshow(img2,vmin=0,vmax=255,cmap=&#39;gray&#39;) sns.histplot(img2.reshape(-1),ax=ax[1,1],bins=15,lw=0,kde=True,color=&#39;C1&#39;) #kde 선을 보면 플랫해서 값들이 골고루 있는 것을 알 수 있음 . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . &#48120;&#49464;&#47676;&#51648; &#54017;(2) . import matplotlib as mpl . fig, ax = plt.subplots() ax.plot([(xi/30)**2 for xi in range(30)],&#39;--o&#39;) ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(3)) # 큰 눈금간격을 3으로 ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(1)) # 작은 눈금간격을 1로 . fig, ax = plt.subplots() ax.plot([(xi/30)**2 for xi in range(30)],&#39;--o&#39;) ax.xaxis.set_major_locator(mpl.ticker.NullLocator()) # x축 눈금삭제 ax.yaxis.set_major_locator(mpl.ticker.NullLocator()) # y축 눈금삭제 . 축 범위조정 . fig, ax = plt.subplots() ax.plot([(xi/30)**2 for xi in range(30)],&#39;--o&#39;) ax.set_ylim(-1,2) ax.set_xlim(-5,35) #plt.ylim(-1,2) 위에랑 같은 코드 #plt.xlim(-5,35) . (-5.0, 35.0) . gcf . plt.plot([1,2,3,2]) fig = plt.gcf() #현재 피규어를 가져와라(뒤늦게라도 코드에 이름을 붙이도록 하려고 등등) . fig.suptitle(&#39;suptitle&#39;) . Text(0.5, 0.98, &#39;suptitle&#39;) . gca - 이름을 붙이고 싶은데 슈퍼 타이틀 말고 axes 이름을 붙이고 싶을 때 사용 . fig . fig . ax = fig.gca() #ax가 피규어 안에 있는 엑시즈에 접근하여 뽑아냄 . ax.set_title(&#39;title&#39;) fig .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/08/sns-scatterplot.html",
            "relUrl": "/python/2022/10/08/sns-scatterplot.html",
            "date": " • Oct 8, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "데이터 시각화 7",
            "content": "import pandas as pd import numpy as np import matplotlib as mpl import seaborn as sns . df1=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/male1.csv&#39;) df2=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/male2.csv&#39;) df3=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/female.csv&#39;) df4=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/foreign.csv&#39;) . _df = pd.concat([pd.concat([df1,df2],axis=1).assign(g=&#39;m&#39;),df3.assign(g=&#39;f&#39;)]) df = pd.concat([_df.assign(g2=&#39;korea&#39;),df4.assign(g2=&#39;foreign&#39;)]).reset_index(drop=True) df #assign(g = &quot;f&quot;) g라는 열을 만들어 &quot;f&quot;라고 만들기 #axis = 1 : 옆으로 붙이기 그냥 붙이면 아래로 붙여짐(axis=0) . w h g g2 . 0 72.788217 | 183.486773 | m | korea | . 1 66.606430 | 173.599877 | m | korea | . 2 69.806324 | 173.237903 | m | korea | . 3 67.449439 | 173.223805 | m | korea | . 4 70.463183 | 174.931946 | m | korea | . ... ... | ... | ... | ... | . 1525 78.154632 | 188.324350 | m | foreign | . 1526 74.754308 | 183.017979 | f | foreign | . 1527 91.196208 | 190.100456 | m | foreign | . 1528 87.770394 | 187.987255 | m | foreign | . 1529 88.021995 | 193.456798 | m | foreign | . 1530 rows × 4 columns . sns.scatterplot(data=df,x=&#39;w&#39;,y=&#39;h&#39;,hue=&#39;g&#39;,style=&#39;g2&#39;) . &lt;AxesSubplot:xlabel=&#39;w&#39;, ylabel=&#39;h&#39;&gt; . #1 기획력 부족 -&gt; 좋은 시각화 많이 볼 것 #2 데이터 프레임에 대한 이해부족-&gt; 타이디 데이터에 대한 개념알기 #3 프로그래밍 능력 -&gt;코딩 공부 열심히 . pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/mpg.csv&#39;) . manufacturer model displ year cyl trans drv cty hwy fl class . 0 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 229 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 230 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 231 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 233 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . displ: 자동차의 엔진크기 . | hwy: 연료의 효율, 동일한 연료로 얼마나 멀리 가느냐? . | 자세한 설명은 R에서 ?mpg를 이용해 스스로 찾아볼 것 . | .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/07/%EB%B3%B4%EC%B6%A9.html",
            "relUrl": "/python/2022/10/07/%EB%B3%B4%EC%B6%A9.html",
            "date": " • Oct 7, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "기후자료 통계분석 코드 분석 과제",
            "content": "import matplotlib.pyplot as plt import xarray as xr #라이브러리 불러오기 dset = xr.open_dataset(‘./Data/sst.mnmean.nc’) #데이터 셋 불러오기. sst=dset.sst.sel() #데이터 셋 중 sst를 선택해서 sst라고 저장 nino34 = sst.where((sst.lat&lt;5) &amp; (sst.lat&gt;-5) &amp; (sst.lon&gt;190) &amp; (sst.lon&lt;240), drop=True).mean(dim=[&#39;lat&#39;,&#39;lon&#39;]) #sst 중 위도가 -5에서 5사이 그리고 경도가 190에서 240 사이에 위치하는 데이터 셋을 고르기, 이 조건을 만족하지 못하는 레이블은 결과에서 삭제하고, 경도와 위도를 평균으로 하는 데이터 셋을 nino34에 저장 clim = nino34.sel(time=slice(‘1982-01&#39;,’2018-12&#39;)).groupby(&#39;time.month&#39;).mean(dim=&#39;time&#39;) #시간을 선택해서 달별로 그룹화, 시간대상 평균을 내고 clim에 저장 anom = (nino34.groupby(&#39;time.month&#39;) - clim).sel(time=slice(‘1981-12&#39;,&#39;2019-02&#39;)) #각 달만큼 그룹화 한 것 - 달마다 평균낸 것 -&gt; 편차를 atom에 저장 nino3mon = anom.rolling(time=5, center=True).mean() #5개월 단위로(롤링)평균 구해서 nino3mon에 저장 ninos = nino3mon[12::12] #달 선택 #그림판 그리기 fig = plt.figure(figsize = (8,6), dpi = 150) ax = fig.subplots() #그림 꾸미기 ax.plot(ninos.time.values, ninos, ‘b-&#39;) ax.axhline(0,color=&#39;black&#39;,linewidth=0.5) # ax.axhline(1.0,color=&#39;black&#39;,linewidth=0.5,linestyle=&#39;dashed&#39;) ax.axhline(-1.0,color=&#39;black&#39;,linewidth=0.5,linestyle=&#39;dashed&#39;) ax.axhline(1.5,color=&#39;black&#39;,linewidth=0.6,linestyle=&#39;dashed&#39;) ax.axhline(-1.5,color=&#39;black&#39;,linewidth=0.6,linestyle=&#39;dashed&#39;) ax.axhline(2.0,color=&#39;black&#39;,linewidth=0.7,linestyle=&#39;dashed&#39;) ax.axhline(-2.0,color=&#39;black&#39;,linewidth=0.7,linestyle=&#39;dashed’) ax.axhline(ninos.std().values,color=&#39;red&#39;,linewidth=0.5,linestyle=&#39;dashed&#39;) #x축 y축 이름 설정 ax.set_xlabel(&#39;Time&#39;) ax.set_ylabel(&#39;[$ degree$C]&#39;) #타이틀 설정하기 ax.set_title(&#39;Nino 3.4 index&#39;) #이미지 저장 plt.savefig(&#39;nino34_index_season.jpg’) plt.show() .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/06/%EA%B8%B0%ED%9B%84%EC%9E%90%EB%A3%8C-%ED%86%B5%EA%B3%84%EB%B6%84%EC%84%9D-%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/python/2022/10/06/%EA%B8%B0%ED%9B%84%EC%9E%90%EB%A3%8C-%ED%86%B5%EA%B3%84%EB%B6%84%EC%84%9D-%EA%B3%BC%EC%A0%9C.html",
            "date": " • Oct 6, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "데이터 시각화 과제 4",
            "content": "import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt . 아래의 그림에 대응하는 그림을 seaborn을 이용하여 그려라 . y1 = np.random.randn(90).cumsum() y2 = np.random.randn(120).cumsum() . plt.plot(y1,&#39;--o&#39;) plt.plot(y2,&#39;--o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fa172cd2b80&gt;] . df = pd.DataFrame({&#39;index&#39; : list(range(90))+list(range(120)), &#39;val&#39; : np.concatenate([y1,y2]), &#39;cat&#39; : [&quot;y1&quot;]*90+[&quot;y2&quot;]*120}) . df . index val cat . 0 0 | 0.512007 | y1 | . 1 1 | 0.836565 | y1 | . 2 2 | 1.040704 | y1 | . 3 3 | 1.397047 | y1 | . 4 4 | 0.765464 | y1 | . ... ... | ... | ... | . 205 115 | -8.820426 | y2 | . 206 116 | -9.655268 | y2 | . 207 117 | -9.507072 | y2 | . 208 118 | -7.630993 | y2 | . 209 119 | -7.234471 | y2 | . 210 rows × 3 columns . sns.lineplot(data = df, x = &quot;index&quot;, y= &quot;val&quot;, hue = &quot;cat&quot;) . &lt;AxesSubplot:xlabel=&#39;index&#39;, ylabel=&#39;val&#39;&gt; . sns.lineplot(data = df, x =&quot;index&quot;, y = &quot;val&quot;, style = &quot;cat&quot;, hue = &quot;cat&quot;, dashes = [(5,1),(9,3)], markers = [&#39;o&#39;,&#39;o&#39;], markersize = 9) . &lt;AxesSubplot:xlabel=&#39;index&#39;, ylabel=&#39;val&#39;&gt; .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/03/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%EA%B3%BC%EC%A0%9C4.html",
            "relUrl": "/python/2022/10/03/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%EA%B3%BC%EC%A0%9C4.html",
            "date": " • Oct 3, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "데이터 시각화 5",
            "content": "import seaborn as sns import matplotlib.pyplot as plt import numpy as np import pandas as pd . 데이터프레임 형태는 long form 과 wide form 이 있다. // 참고로 long form이 더 우수한 저장형태에요! . wide-df = [array1,array2,array3] | long-df = [array_val, array_cat] | . 데이터 프레임을 무조건 만들어야 한다. . matplotlib이랑 매우 비슷함. . sns.boxplot . y1=[75,75,76,76,77,77,79,79,79,98] y2=[76,76,77,77,78,78,80,80,80,81] . plt.boxplot([y1, y2]); . sns wide df . df1 = pd.DataFrame({1:y1, 2:y2}) ##만드는 게 진짜 중요 df1 . 1 2 . 0 75 | 76 | . 1 75 | 76 | . 2 76 | 77 | . 3 76 | 77 | . 4 77 | 78 | . 5 77 | 78 | . 6 79 | 80 | . 7 79 | 80 | . 8 79 | 80 | . 9 98 | 81 | . sns.boxplot(data = df1) #y1 y2 알아서 그려줌 . &lt;AxesSubplot:&gt; . sns long df . df2 = pd.DataFrame({&quot;score&quot; : y1+y2, &quot;class&quot; : [&#39;A&#39;]*len(y1)+[&#39;b&#39;]*len(y2)}) . df2 #와이드 폼은 데이터 갯수가 다르면 저장 불가 -&gt; 롱폼이 더 좋음 . score class . 0 75 | A | . 1 75 | A | . 2 76 | A | . 3 76 | A | . 4 77 | A | . 5 77 | A | . 6 79 | A | . 7 79 | A | . 8 79 | A | . 9 98 | A | . 10 76 | b | . 11 76 | b | . 12 77 | b | . 13 77 | b | . 14 78 | b | . 15 78 | b | . 16 80 | b | . 17 80 | b | . 18 80 | b | . 19 81 | b | . sns.boxplot(data=df2,x=&#39;class&#39;,y=&#39;score&#39;) . &lt;AxesSubplot:xlabel=&#39;class&#39;, ylabel=&#39;score&#39;&gt; . sns.array . sns.boxplot(y=y1) #== data=y1 . &lt;AxesSubplot:&gt; . sns.boxplot(x=y1) #x축에 그리면 boxplot이 뒤집어짐!! . &lt;AxesSubplot:&gt; . sns.histplot . x= np.random.randn(10000) y= np.random.randn(10000) +1 . &#48373;&#49845; . plt.hist(x,alpha=0.5) plt.hist(y,alpha=0.5); #alpha == 투명도 . plt.hist([x,y]); . sns: wide df . df1 = pd.DataFrame({&quot;x&quot; : x, &quot;y&quot; : y}) df1 . x y . 0 0.883839 | 0.742332 | . 1 -0.741664 | 0.904649 | . 2 -0.482733 | 0.397702 | . 3 -0.496118 | 2.008637 | . 4 -1.259945 | 3.014091 | . ... ... | ... | . 9995 -0.198176 | 1.094588 | . 9996 -0.004803 | 1.000243 | . 9997 1.214724 | 0.691808 | . 9998 0.343697 | 3.017497 | . 9999 -0.308866 | 2.813727 | . 10000 rows × 2 columns . sns.histplot(data = df1) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . sns.histplot(data=df1,bins=20,kde=True,element=&quot;step&quot;) #element = &quot;step&quot; : 안에 선 없이 예쁘게 그려짐 #kde = 추세선 . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . sns.histplot(data=df1,bins=20,kde=True,element=&quot;step&quot;, lw = 0) #선 굵기 정하기 mpl랑 동일! #선 없앨 때 유용 . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . sns long df . df2=pd.DataFrame({&#39;val&#39;:np.concatenate([x,y]), &#39;var&#39;:[&#39;x&#39;]*len(x) + [&#39;y&#39;]*len(y)}) df2 #리스트가 아니므로 x+y안 됨. np.concatenate사용해서 붙여주기 . val var . 0 0.883839 | x | . 1 -0.741664 | x | . 2 -0.482733 | x | . 3 -0.496118 | x | . 4 -1.259945 | x | . ... ... | ... | . 19995 1.094588 | y | . 19996 1.000243 | y | . 19997 0.691808 | y | . 19998 3.017497 | y | . 19999 2.813727 | y | . 20000 rows × 2 columns . sns.histplot(data=df2,x=&#39;val&#39;,hue=&#39;var&#39;,bins=20,kde=True,lw=0) #hue = &#39;var&#39; -&gt; 색 . &lt;AxesSubplot:xlabel=&#39;val&#39;, ylabel=&#39;Count&#39;&gt; . sns lineplot . np.random.seed(43052) ϵ = np.random.randn(100) . cumsum . sns.histplot(data = x) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . np.cumsum(np.array([1, 2,3])) #누적된 값이 더해짐! . array([1, 3, 6]) . y = np.cumsum(ϵ) #입실론을 다 더한 것 . plt.plot(ϵ,&#39;--o&#39;) #입실론에 대한 그림 . [&lt;matplotlib.lines.Line2D at 0x7ff1e0c86520&gt;] . plt.plot(y,&#39;--o&#39;) #y에 대한 그림 . [&lt;matplotlib.lines.Line2D at 0x7ff22acef0a0&gt;] . sns array . sns.lineplot(data=ϵ) . &lt;AxesSubplot:&gt; . sns.lineplot(data=y) . &lt;AxesSubplot:&gt; . sns wide df . df1 = pd.DataFrame({&quot;epsilon&quot; : ϵ, &quot;y&quot; : y}) df1 . epsilon y . 0 0.383420 | 0.383420 | . 1 1.084175 | 1.467595 | . 2 1.142778 | 2.610373 | . 3 0.307894 | 2.918267 | . 4 0.237787 | 3.156054 | . ... ... | ... | . 95 1.308688 | -10.598788 | . 96 0.405376 | -10.193412 | . 97 -0.185070 | -10.378481 | . 98 1.055388 | -9.323094 | . 99 1.187014 | -8.136079 | . 100 rows × 2 columns . sns.lineplot(data = df1, dashes = False) . &lt;AxesSubplot:&gt; . sns.lineplot(data = df1, dashes = [(3,1),(15,3)], markers = [&quot;o&quot;, &quot;o&quot;]) #대시들 선 간격 바꾸기 . &lt;AxesSubplot:&gt; . sns long df . df2 = pd.DataFrame({&#39;index&#39; : list(range(100))*2, &#39;val&#39; : np.concatenate([ϵ,y]), &#39;cat&#39; : [&quot;eps&quot;]*100+[&quot;y&quot;]*100}) #1~100/1~100 . df2 . index val cat . 0 0 | 0.383420 | eps | . 1 1 | 1.084175 | eps | . 2 2 | 1.142778 | eps | . 3 3 | 0.307894 | eps | . 4 4 | 0.237787 | eps | . ... ... | ... | ... | . 195 95 | -10.598788 | y | . 196 96 | -10.193412 | y | . 197 97 | -10.378481 | y | . 198 98 | -9.323094 | y | . 199 99 | -8.136079 | y | . 200 rows × 3 columns . sns.lineplot(data = df2, x =&quot;index&quot;, y = &quot;val&quot;, hue = &quot;cat&quot;) . &lt;AxesSubplot:xlabel=&#39;index&#39;, ylabel=&#39;val&#39;&gt; . sns.lineplot(data = df2, x =&quot;index&quot;, y = &quot;val&quot;, style = &quot;cat&quot;, hue = &quot;cat&quot;) #스타일이랑 색을 카테고리에 맞게 . &lt;AxesSubplot:xlabel=&#39;index&#39;, ylabel=&#39;val&#39;&gt; . sns scatterplot . np.random.seed(43052) ϵ = np.random.randn(100) y = np.cumsum(ϵ) . ϵ1 = ϵ[:-1] #t-1의 시점, 처음부터 마지막 하나빼고 ϵ2 = ϵ[1:] #t의 시점, 두번째부터 마지막까지 . y1 = y[:-1] #t-1의 시점 y2 = y[1:] #t의 시점 . plt.plot(ϵ1, ϵ2, &#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff1e8d9ca90&gt;] . np.corrcoef(ϵ1, ϵ2) #상관관계 0 -&gt; 독립 . array([[1. , 0.05289696], [0.05289696, 1. ]]) . plt.plot(y1, y2, &#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff22b725f10&gt;] . np.corrcoef(y1, y2) #독립아님 . array([[1. , 0.97237553], [0.97237553, 1. ]]) . . y1 = np.random.randn(90).cumsum() y2 = np.random.randn(120).cumsum() . plt.plot(y1,&#39;--o&#39;) plt.plot(y2,&#39;--o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff208a5ca30&gt;] . sns.histplot(x = x) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/03/seaborn.html",
            "relUrl": "/python/2022/10/03/seaborn.html",
            "date": " • Oct 3, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "빅데이터 개론 복습 2",
            "content": "3-1 &#49707;&#51088; . import math import sys . type(8) . int . type(8.0) . float . x = 1 y = 3 . x/y . type(x/y) . float . 소수점 17 자리 이상의 아주 작은 실수는 정확하게 숫자의 값을 저장하지 못한다. . 1/3 + 0.0000000000000001 # 소수점 16자리 부동소수점 . 0.3333333333333334 . 1/3 == (1/3 + 0.0000000000000001) # 소수점 17자리 부동소수점 . False . 1/3 == (1/3 + 0.00000000000000001) #소수점 17개 이상은 컴퓨터에서 받아주지 못하는 모습 . True . 0.55 - 0.54 . 0.010000000000000009 . 두 수의 차이 값이 우리가 생각하는 결과와 다를 수 있다. . 0.55 - 0.54 == 0.01 . False . 파이썬이 대수적으로 구별할 수 있는 가장 작은 수는 2.220446049250313e-16 이다. . 엡실론(Machine epsilon)이라고 부르며 파이썬의 계산 엡실론은 sys.float_info.epsilon 으로 알 수 있다. . machine_epsilon = sys.float_info.epsilon machine_epsilon . 2.220446049250313e-16 . 파이썬에서 큰 수를 출력해주는 경우 과학적 표기법(scientific notation)을 사용한다. 아래 식에서 2.0e+306는 2.0×10306 을 의미한다. 큰 수 2.0×10308 은 파이썬의 부동소수점 형식으로 저장할 수 없기 때문에 결과를 inf 로 나타낸다. . 2.0e+306 #2.0×10의306제곱 . 2e+306 . 2.0e306 * 100 . inf . 3-2 &#47928;&#51088;&#50676; . name_3 = &quot;이철수&quot; name_3[0] . &#39;이&#39; . name_3[1:3] . &#39;철수&#39; . text_5 = &#39;There is a desk&#39; text_5 . &#39;There is a desk&#39; . text_5.replace(&quot;is&quot;, &quot;was&quot;) #문자열 따옴표 잊지 말기 . &#39;There was a desk&#39; . text_5.upper() # 문자열을 모두 대문자로 . &#39;THERE IS A DESK&#39; . text_5.count(&#39;e&#39;) # 괄호안에 주어진 문자열이 몇 번 나타나는지 . 3 . text_5.split(sep=&#39; &#39;) # sep= 으로 지정된 문자열을 사용하여 문자열을 나누어서 리스트로 저장 . [&#39;There&#39;, &#39;is&#39;, &#39;a&#39;, &#39;desk&#39;] . &#49892;&#49845; . 본인의 단대, 학과, 학번, 이름(영문)을 각각 문자열로 정의하여라. 정의된 문자열을 하나로 결합하여라. . | 위에서 정의된 본인의 이름을 모두 대문자로 바꾸어라. . | 위에서 결합된 문자열에서 본인의 이름을 국문으로 바꾸어라. . | 본인의 생년월일을 다음과 같은 형식으로 표기하는 문자열을 정의하여라. 1990/02/16 . | 생년월일에서 년에 해당하는 정보만을 추출하여라. . | 생년월일을 년, 월, 일 새 부분으로 나누어라. . | a = &quot;인문대&quot; b = &quot;스페인중남미학과&quot; c = &quot;201821502&quot; d = &quot;Hyeji&quot; aa = a +&quot; &quot;+ b +&quot; &quot;+ c +&quot; &quot;+ d aa . &#39;인문대 스페인중남미학과 201821502 Hyeji&#39; . d.upper() . &#39;HYEJI&#39; . aa.replace(d, &quot;혜지&quot;) . &#39;인문대 스페인중남미학과 201821502 혜지&#39; . e = &quot;1000/02/01&quot; . e[5:7] . &#39;02&#39; . e[0:4] . &#39;1000&#39; . e.split(&quot;/&quot;) . [&#39;1000&#39;, &#39;02&#39;, &#39;01&#39;] . f1, f2, f3 = e.split(sep = &quot;/&quot;) f2 . &#39;02&#39; . &#54665;&#47148;(array) . 이 과목에서는 행렬 형식보다 데이터프레임 형식의 자료를 주로 이용한다. 이 장에서는 라이브러리 numpy 에서 제공하는 행렬의 간단한 사용법만 살펴볼것이다. . import numpy as np . a = np.array([1,2,3,4,5,6]) a . array([1, 2, 3, 4, 5, 6]) . 행렬은 리스트와 달리 같은 형식의 자료만 모아 놓을 수 있다. . np.array([1, 2, &#39;a&#39;]) #정의 안 됨 -&gt; 같은 형식으로만 실행하기 . array([&#39;1&#39;, &#39;2&#39;, &#39;a&#39;], dtype=&#39;&lt;U21&#39;) . a[0] . 1 . a[[0, 3, 5]] #행렬은 다음과 같이 순서의 위치를 []에 넣어서 부를 수 있음 . array([1, 4, 6]) . a[0:3] . array([1, 2, 3]) . . np.arange(6) . array([0, 1, 2, 3, 4, 5]) . np.arange(2, 10, 2) #짝수 . array([2, 4, 6, 8]) . np.arange(0, 10, 3) #0포함 3의 배수 . array([0, 3, 6, 9]) . np.arange(10, -10, -2) . array([10, 8, 6, 4, 2, 0, -2, -4, -6, -8]) . 2차원 행렬 - reshape() . b = np.arange(1, 9).reshape(2, 4) b . array([[1, 2, 3, 4], [5, 6, 7, 8]]) . c = np.array([[1, 2, 3, 4], [5, 6, 7, 8]]) c . array([[1, 2, 3, 4], [5, 6, 7, 8]]) . b[0,0] #2차원에서 일부를 지정해 보는 법 . 1 . b[0, 0:4] #1행, 1-4열 . array([1, 2, 3, 4]) . b[0:2, 1:3] . array([[2, 3], [6, 7]]) . c = b[0:2,1] #열이 하나밖에 없으므로 일차원 배열로 보여줌!!!!!!! c . array([2, 6]) . c.ndim . 1 . c_1 = c.reshape(2,1) #2차원으로 바꾸기 c_1 . array([[2], [6]]) . d = b[1, 0:3] d . array([5, 6, 7]) . d.ndim . 1 . &#47928;&#51228; . 다음과 같은 코드를 먼저 실행하고 물음에 답하여라 . A = np.array([1, 4, 2, 5, 3]) . 1) A의 1, 3, 5 번째 원소를 추출하여라 2) A의 마지막 원소만 제외한 나머지로 이루어진 1차원 배열을 추출하여라 3) 5에서 1씩 감소하는 길이가 5인 1차원 배열을 만들고 B라 명명하여라 4) A와 B를 순서대로 연결하는 1차원 배열 C를 만들어라(concatenate([x,y])이용) 5) 위에서 만들어진 C로부터 A가 첫번째 행, B를 두번째 행이 되도록 2차원 배열(행렬) D를 정의 하여라 6) D의 첫 두번째 행과 첫 두번째 열로 이루어진 부분행렬을 추출하여라 7) D의 세 번째 열로만 이루어진 배열을 추출하여라. 단, 1차원 배열이 아니라 2차원 배열의 속성을 그대로 가지도록 하여라 . import numpy as np . A = np.array([1, 4, 2, 5, 3]) . A[[0,2,4]] #1 . array([1, 2, 3]) . A[0:4] . array([1, 4, 2, 5]) . B = np.arange(5, 0, -1) B . array([5, 4, 3, 2, 1]) . C = np.concatenate([A,B]) C . array([1, 4, 2, 5, 3, 5, 4, 3, 2, 1]) . D = C.reshape(2, 5) #2행 5열 인것을 잊지말기 행만 2개가 아닌 열도 신경써야함 D . array([[1, 4, 2, 5, 3], [5, 4, 3, 2, 1]]) . D[0:2, 0:2] . array([[1, 4], [5, 4]]) . D[:,2].reshape(2,1) #리솊을 해서 2차원으로 만들기 . array([[2], [3]]) .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/10/02/(%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B0%9C%EB%A1%A0-3-1~3-3).html",
            "relUrl": "/python/2022/10/02/(%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B0%9C%EB%A1%A0-3-1~3-3).html",
            "date": " • Oct 2, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "빅데이터 개론 복습1",
            "content": "2-1 &#54364;&#54788;&#49885;&#44284; &#48320;&#49688; . hour_rate = 10000 month_working_days = 20 day_working_hours = 4 month_pay = hour_rate * month_working_days * day_working_hours month_pay . 800000 . text_2 =&#39;you can &#39;t come&#39; #역슬래시로 구분하기 text_2 . &#34;you can&#39;t come&#34; . print(&quot;첫 번째 줄 n두 번째 줄&quot;) . 첫 번째 줄 두 번째 줄 . text_4 = &#39;C: some name&#39; print(text_4) . C: some ame . text_5 = r&#39;C: some name&#39; print(text_5) . C: some name . 라이브러리와 함수 | . import math . math.sin(2) . 0.9092974268256817 . math.log(100) . 4.605170185988092 . 리스트 | . list_1 = [1, 2, 0.5, &#39;chair&#39;] list_1 . [1, 2, 0.5, &#39;chair&#39;] . list_2 = [ list_1, &quot;A&quot;, [1,2,3] ] list_2 . [[1, 2, 0.5, &#39;chair&#39;], &#39;A&#39;, [1, 2, 3]] . 파이썬의 인덱스는 1이 아닌 0 부터 시작하므로 이를 언제나 유념해야 한다 . squares = [1, 4, 9, 16, 25] . squares[0] . 1 . squares[4] . 25 . squares[:1] . [1] . squares[:-1] . [1, 4, 9, 16] . squares[-1:] . [25] . 1 in [1, 2, 3, 4] . True . a = 5 a in [1, 2, 3, 4, 5] . True . &#49892;&#49845; . hstudent.csv&#39;는 20명의 고등학생 성별, 학년, 키(cm), 몸무게(kg)를 조사한 자료이다. | 체질량지수는 몸무게(kg)를 키의 제곱(m)으로 나눈 값입니다. 5번 학생의 체질량지수는? | 10번 학생의 체질량지수는? | . | 학생의 키와 몸무게를 각각 height와 weight에 저장하고, height와 weight를 사용하여 체질량지수 계산 5번 과 10번 학생 각각에 대하여 계산한 후 bmi5와 bmi10에 저장 | bmi5와 bmi10의 크기 비교 결과 print함수를 사용하여 보여주기 | . | 1번부터 5번까지의 학생 키를 원소로 가지는 리스트 변수 height1_5생성 1번부터 3번까지 학생의 키 추출 | . | . 나는 전북대학교 학과 이름 입니다. (예, 나는 전북대학교 통계학과 최혜미입니다) 위 문자열을 값으로 가지는 변수 name_dept를 생성 | 변수 name_dept에서 전북대학교 추출 | . | df = pd.read_csv(&quot;hstudent.csv&quot;) df . gender grade height weight . 0 1 | 3 | 183 | 82 | . 1 2 | 1 | 168 | 52 | . 2 2 | 1 | 160 | 48 | . 3 2 | 2 | 160 | 50 | . 4 1 | 1 | 160 | 79 | . 5 1 | 2 | 180 | 73 | . 6 2 | 2 | 183 | 60 | . 7 1 | 1 | 170 | 66 | . 8 1 | 3 | 170 | 74 | . 9 1 | 3 | 185 | 57 | . 10 1 | 2 | 165 | 54 | . 11 2 | 1 | 170 | 50 | . 12 2 | 1 | 152 | 60 | . 13 2 | 3 | 173 | 63 | . 14 1 | 1 | 145 | 57 | . 15 1 | 3 | 163 | 77 | . 16 2 | 2 | 178 | 50 | . 17 2 | 2 | 163 | 57 | . 18 2 | 2 | 168 | 54 | . 19 2 | 3 | 170 | 57 | . height = df[&#39;height&#39;] weight = df[&#39;weight&#39;] . bmi5 = weight[4]/height[4]**2 bmi10 = weight[9]/height[9]**2 print(bmi5, bmi10) . 0.0030859375 0.0016654492330168006 . height1_5 = height[0:5] height1_5[0:3] . 0 183 1 168 2 160 Name: height, dtype: int64 . height1_5 = list(height[0:5]) height1_5[0:3] . [183, 168, 160] . # weight = [82, 52, 48, 50, 79, 73, 60, 66, 74, 57, 54, 50, 60, 63, 57, 77, 50, 57, 54, 57] . name_debt = &quot;나는 전북대학교 스페인중남미학과 김혜지입니다.&quot; name_debt[3:8] . &#39;전북대학교&#39; . 2-2 &#54032;&#45796;&#49828; &#45936;&#51060;&#53552; &#54532;&#47112;&#51076; . import pandas as pd . df = pd.DataFrame({ &#39;name&#39; : [&#39;이철수&#39;, &#39;김영희&#39;, &#39;홍길동&#39;, &#39;John Smith&#39;], &#39;sex&#39; : [&#39;M&#39;, &#39;F&#39;, &#39;M&#39;, &#39;M&#39;], &#39;age&#39; : [23, 25, 21, 33] }) . df . name sex age . 0 이철수 | M | 23 | . 1 김영희 | F | 25 | . 2 홍길동 | M | 21 | . 3 John Smith | M | 33 | . 슬라이싱 | . df[[&#39;name&#39;, &#39;age&#39;]] #두 개 이상의 열을 슬라이싱 하기위해서는 리스트를 사용하기 . name age . 0 이철수 | 23 | . 1 김영희 | 25 | . 2 홍길동 | 21 | . 3 John Smith | 33 | . #데이터 프레임 열을 슬라이스 하는 경우는 마침표 사용해서 슬라이싱이 가능 df.age . 0 23 1 25 2 21 3 33 Name: age, dtype: int64 . df[df[&#39;age&#39;] &gt;= 25] #df[&#39;age&#39;] &gt;= 25는 참, 거짓으로 구성된 시리즈 -&gt; 슬라이싱 하기 위해서는 df을 한 번 더 씌어주면 됨 . name sex age . 1 김영희 | F | 25 | . 3 John Smith | M | 33 | . 데이터 프레임 메소드 | . df.describe() #describe() : 숫자로 구성된 열의 기초 통계량을 구하는 표현식 . age . count 4.000000 | . mean 25.500000 | . std 5.259911 | . min 21.000000 | . 25% 22.500000 | . 50% 24.000000 | . 75% 27.000000 | . max 33.000000 | . df.max() #각 열의 최대값을 구하는 작업을 수행 ?왜 맥스 값을 찍었는데 홍길동 이름이 나오지? #한글은 가나다순, 영어는 알파벳 순으로 max값이 뽑힌다. . name 홍길동 sex M age 33 dtype: object . df.shape . (4, 3) . df.iloc[1,0] . &#39;김영희&#39; . df.iloc[2,2] . 21 . &#47928;&#51228;1 . 사진과 같은 데이터 프레임 만들기 | 데이터 프레임의 shape를 출력 | 평균 면적(area)을 계산하여라 | 인구수가 2000만명 이하인 주들을 골라내어라. 또한 해당하는 주의 평균 밀도를 구해보아라 | 첫 3개의 행과 첫 2개의 열로 이루어진 sub-dataframe을 추출하여라 | New York의 인구(pop)를 추출하여라 | df = pd.DataFrame({&quot;area&quot; : [423967, 695662, 141297, 170312, 149995], &quot;pop1&quot; : [38332521, 26448193, 19651127, 19552860, 12882135], &quot;density&quot; : [90.000000, 38.018740, 139.076746, 114.806121, 85.883763] }, index = [&quot;Califonia&quot;, &quot;Texas&quot;, &quot;New York&quot;, &quot;Flprida&quot;, &quot;Illinois&quot;]) df . area pop1 density . Califonia 423967 | 38332521 | 90.000000 | . Texas 695662 | 26448193 | 38.018740 | . New York 141297 | 19651127 | 139.076746 | . Flprida 170312 | 19552860 | 114.806121 | . Illinois 149995 | 12882135 | 85.883763 | . df.shape . (5, 3) . df[&quot;area&quot;].mean() #mean다음에 괄호 잊지 말기 () 중요!! . 316246.6 . df[df[&quot;pop1&quot;] &lt;= 20000000][&quot;density&quot;].mean() #mean() 다음에 괄호 필수, 데이터 프레임 옆에 붙여서 밀도의 평균 계산 가능 . 113.25554333333334 . df.iloc[:3,:2] # iloc 사용하기 . area pop1 . Califonia 423967 | 38332521 | . Texas 695662 | 26448193 | . New York 141297 | 19651127 | . df.iloc[2,1] . 19651127 . df[&quot;pop1&quot;][&quot;New York&quot;] # df를 뽑으려면 무조건 열 먼저 실행 후 행 선택하기(행 먼저하면 오류 발생) . 19651127 . 2-3 &#44256;&#49549;&#50676;&#52264; &#50668;&#44061; &#49688;&#49569;&#51088;&#47308; . import pandas as pd import matplotlib.pyplot as plt from matplotlib import rc %matplotlib inline rc(&#39;font&#39;, family=&#39;AppleGothic&#39;) plt.rcParams[&#39;axes.unicode_minus&#39;] = False plt.rcParams[&quot;figure.figsize&quot;] = (10,5) . url =&quot;https://ilovedata.github.io/teaching/bigdata2/data/train-data-01.csv&quot; train_raw_data = pd.read_csv(url) train_raw_data . TRAIN_NO DATE STATION_DEPART STATION_ARRV NUM_PASSENGER . 0 2 | 20190701 | 서울 | 대전 | 106.0 | . 1 2 | 20190702 | 서울 | 대전 | 113.0 | . 2 2 | 20190703 | 서울 | 대전 | 146.0 | . 3 2 | 20190704 | 서울 | 대전 | 84.0 | . 4 2 | 20190705 | 서울 | 대전 | 105.0 | . ... ... | ... | ... | ... | ... | . 1764 6 | 20190726 | 울산 | 부산 | 10.0 | . 1765 6 | 20190727 | 울산 | 부산 | 6.0 | . 1766 6 | 20190728 | 울산 | 부산 | 21.0 | . 1767 6 | 20190729 | 울산 | 부산 | 12.0 | . 1768 6 | 20190730 | 울산 | 부산 | 11.0 | . 1769 rows × 5 columns . num_train = train_raw_data[&quot;TRAIN_NO&quot;].unique() num_train . array([2, 5, 6]) . 다음 3개의 조건을 모두 만족하는 행들을 추출 . 열차번호가 2번이다. . 출발역은 서울역이다. . 도착역은 부산역이다. . a = train_raw_data[&quot;TRAIN_NO&quot;] == 2 b = train_raw_data[&quot;STATION_DEPART&quot;] == &quot;서울&quot; c = train_raw_data[&quot;STATION_ARRV&quot;] == &quot;부산&quot; d = a &amp; b &amp; c d . 0 False 1 False 2 False 3 False 4 False ... 1764 False 1765 False 1766 False 1767 False 1768 False Length: 1769, dtype: bool . train2 = train_raw_data[d] #습관처럼 df에 넣지 말자 정의된 데이터 프레임에 넣어야 한다. df[a] 이렇게 표현할 수 있는 이유는 df가 정의되어 있는 데이터 프레임이기 때문이다. . train2 . TRAIN_NO DATE STATION_DEPART STATION_ARRV NUM_PASSENGER . 60 2 | 20190701 | 서울 | 부산 | 613.0 | . 61 2 | 20190702 | 서울 | 부산 | 546.0 | . 62 2 | 20190703 | 서울 | 부산 | 492.0 | . 63 2 | 20190704 | 서울 | 부산 | 615.0 | . 64 2 | 20190705 | 서울 | 부산 | 572.0 | . 65 2 | 20190706 | 서울 | 부산 | 598.0 | . 66 2 | 20190707 | 서울 | 부산 | 326.0 | . 67 2 | 20190708 | 서울 | 부산 | 552.0 | . 68 2 | 20190709 | 서울 | 부산 | 540.0 | . 69 2 | 20190710 | 서울 | 부산 | 499.0 | . 70 2 | 20190711 | 서울 | 부산 | 562.0 | . 71 2 | 20190712 | 서울 | 부산 | 601.0 | . 72 2 | 20190713 | 서울 | 부산 | 655.0 | . 73 2 | 20190714 | 서울 | 부산 | 371.0 | . 74 2 | 20190715 | 서울 | 부산 | 557.0 | . 75 2 | 20190716 | 서울 | 부산 | 525.0 | . 76 2 | 20190717 | 서울 | 부산 | 557.0 | . 77 2 | 20190718 | 서울 | 부산 | 585.0 | . 78 2 | 20190719 | 서울 | 부산 | 593.0 | . 79 2 | 20190720 | 서울 | 부산 | 620.0 | . 80 2 | 20190721 | 서울 | 부산 | 355.0 | . 81 2 | 20190722 | 서울 | 부산 | 548.0 | . 82 2 | 20190723 | 서울 | 부산 | 557.0 | . 83 2 | 20190724 | 서울 | 부산 | 550.0 | . 84 2 | 20190725 | 서울 | 부산 | 593.0 | . 85 2 | 20190726 | 서울 | 부산 | 551.0 | . 86 2 | 20190727 | 서울 | 부산 | 615.0 | . 87 2 | 20190728 | 서울 | 부산 | 530.0 | . 88 2 | 20190729 | 서울 | 부산 | 589.0 | . 89 2 | 20190730 | 서울 | 부산 | 503.0 | . train2.plot(x=&#39;DATE&#39;, y=&quot;NUM_PASSENGER&quot;) #날짜별 승객데이터 확인 가능 . &lt;AxesSubplot:xlabel=&#39;DATE&#39;&gt; . to_datetime() :날짜 형식 변환 ex)format=&#39;%Y%m%d&#39; . train2[&#39;DATE2&#39;] = pd.to_datetime(train2[&#39;DATE&#39;], format=&#39;%Y%m%d&#39;) train2 . /var/folders/xh/xtwkcbrj0_l1srsb4r5pc3l00000gn/T/ipykernel_31932/279216404.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy train2[&#39;DATE2&#39;] = pd.to_datetime(train2[&#39;DATE&#39;], format=&#39;%Y%m%d&#39;) . TRAIN_NO DATE STATION_DEPART STATION_ARRV NUM_PASSENGER DATE2 . 60 2 | 20190701 | 서울 | 부산 | 613.0 | 2019-07-01 | . 61 2 | 20190702 | 서울 | 부산 | 546.0 | 2019-07-02 | . 62 2 | 20190703 | 서울 | 부산 | 492.0 | 2019-07-03 | . 63 2 | 20190704 | 서울 | 부산 | 615.0 | 2019-07-04 | . 64 2 | 20190705 | 서울 | 부산 | 572.0 | 2019-07-05 | . 65 2 | 20190706 | 서울 | 부산 | 598.0 | 2019-07-06 | . 66 2 | 20190707 | 서울 | 부산 | 326.0 | 2019-07-07 | . 67 2 | 20190708 | 서울 | 부산 | 552.0 | 2019-07-08 | . 68 2 | 20190709 | 서울 | 부산 | 540.0 | 2019-07-09 | . 69 2 | 20190710 | 서울 | 부산 | 499.0 | 2019-07-10 | . 70 2 | 20190711 | 서울 | 부산 | 562.0 | 2019-07-11 | . 71 2 | 20190712 | 서울 | 부산 | 601.0 | 2019-07-12 | . 72 2 | 20190713 | 서울 | 부산 | 655.0 | 2019-07-13 | . 73 2 | 20190714 | 서울 | 부산 | 371.0 | 2019-07-14 | . 74 2 | 20190715 | 서울 | 부산 | 557.0 | 2019-07-15 | . 75 2 | 20190716 | 서울 | 부산 | 525.0 | 2019-07-16 | . 76 2 | 20190717 | 서울 | 부산 | 557.0 | 2019-07-17 | . 77 2 | 20190718 | 서울 | 부산 | 585.0 | 2019-07-18 | . 78 2 | 20190719 | 서울 | 부산 | 593.0 | 2019-07-19 | . 79 2 | 20190720 | 서울 | 부산 | 620.0 | 2019-07-20 | . 80 2 | 20190721 | 서울 | 부산 | 355.0 | 2019-07-21 | . 81 2 | 20190722 | 서울 | 부산 | 548.0 | 2019-07-22 | . 82 2 | 20190723 | 서울 | 부산 | 557.0 | 2019-07-23 | . 83 2 | 20190724 | 서울 | 부산 | 550.0 | 2019-07-24 | . 84 2 | 20190725 | 서울 | 부산 | 593.0 | 2019-07-25 | . 85 2 | 20190726 | 서울 | 부산 | 551.0 | 2019-07-26 | . 86 2 | 20190727 | 서울 | 부산 | 615.0 | 2019-07-27 | . 87 2 | 20190728 | 서울 | 부산 | 530.0 | 2019-07-28 | . 88 2 | 20190729 | 서울 | 부산 | 589.0 | 2019-07-29 | . 89 2 | 20190730 | 서울 | 부산 | 503.0 | 2019-07-30 | . train2.plot(x=&#39;DATE2&#39;, y=&quot;NUM_PASSENGER&quot;); . &#44536;&#47353;&#48324; &#48516;&#49437; . . train_raw_data[&#39;DATE2&#39;] = pd.to_datetime(train_raw_data[&#39;DATE&#39;], format=&#39;%Y%m%d&#39;) train_raw_data . TRAIN_NO DATE STATION_DEPART STATION_ARRV NUM_PASSENGER DATE2 . 0 2 | 20190701 | 서울 | 대전 | 106.0 | 2019-07-01 | . 1 2 | 20190702 | 서울 | 대전 | 113.0 | 2019-07-02 | . 2 2 | 20190703 | 서울 | 대전 | 146.0 | 2019-07-03 | . 3 2 | 20190704 | 서울 | 대전 | 84.0 | 2019-07-04 | . 4 2 | 20190705 | 서울 | 대전 | 105.0 | 2019-07-05 | . ... ... | ... | ... | ... | ... | ... | . 1764 6 | 20190726 | 울산 | 부산 | 10.0 | 2019-07-26 | . 1765 6 | 20190727 | 울산 | 부산 | 6.0 | 2019-07-27 | . 1766 6 | 20190728 | 울산 | 부산 | 21.0 | 2019-07-28 | . 1767 6 | 20190729 | 울산 | 부산 | 12.0 | 2019-07-29 | . 1768 6 | 20190730 | 울산 | 부산 | 11.0 | 2019-07-30 | . 1769 rows × 6 columns . 이제 날짜의 형식을 가진 변수 DATE2 를 아용하여 요일을 나타내는 새로운 변수 DAYOFWEEK 를 만들어 보자. .dt.dayofweek 를 적용하면 각 날짜에 대응하는 요일을 구해준다. . train_raw_data[&quot;DAYOFWEEK&quot;] = train_raw_data[&#39;DATE2&#39;].dt.dayofweek . 요일별, 구간별로 탑승객 수의 평균을 구하기 위하여 필요한 변수를 가진 데이터프레임을 먼저 만든다. . 요일별, 구간별 분석을 하려면 다음과 같은 3개의 변수(요일, 출발역, 도착역)로 자료를 그룹화(grouping)해야한다. . train_groub_data = train_raw_data[[&#39;STATION_DEPART&#39;, &#39;STATION_ARRV&#39;,&#39;DAYOFWEEK&#39;,&#39;NUM_PASSENGER&#39;]] . summary_data = train_raw_data.groupby([&#39;STATION_DEPART&#39;,&#39;STATION_ARRV&#39;,&#39;DAYOFWEEK&#39;]).mean() summary_data . TRAIN_NO DATE NUM_PASSENGER . STATION_DEPART STATION_ARRV DAYOFWEEK . 광명 대전 0 5.5 | 20190715.0 | 16.300 | . 1 5.5 | 20190716.0 | 15.200 | . 2 5.5 | 20190713.5 | 20.750 | . 3 5.5 | 20190714.5 | 21.125 | . 4 5.5 | 20190715.5 | 18.125 | . ... ... ... ... | ... | ... | . 행신 서울 2 2.0 | 20190713.5 | 12.750 | . 3 2.0 | 20190714.5 | 10.000 | . 4 2.0 | 20190715.5 | 8.250 | . 5 2.0 | 20190716.5 | 7.500 | . 6 2.0 | 20190717.5 | 5.000 | . 224 rows × 3 columns . 위의 그룹화 결과 자료는 다루기가 까다로와서 각 그룹에 대한 값을 열로 다시 만들어 주는 것이 좋다. . reset_index()사용, inplace=True 은 실제로 데이터프레임에 적용하라는 의미 . summary_data.reset_index(inplace=True) summary_data . STATION_DEPART STATION_ARRV DAYOFWEEK TRAIN_NO DATE NUM_PASSENGER . 0 광명 | 대전 | 0 | 5.5 | 20190715.0 | 16.300 | . 1 광명 | 대전 | 1 | 5.5 | 20190716.0 | 15.200 | . 2 광명 | 대전 | 2 | 5.5 | 20190713.5 | 20.750 | . 3 광명 | 대전 | 3 | 5.5 | 20190714.5 | 21.125 | . 4 광명 | 대전 | 4 | 5.5 | 20190715.5 | 18.125 | . ... ... | ... | ... | ... | ... | ... | . 219 행신 | 서울 | 2 | 2.0 | 20190713.5 | 12.750 | . 220 행신 | 서울 | 3 | 2.0 | 20190714.5 | 10.000 | . 221 행신 | 서울 | 4 | 2.0 | 20190715.5 | 8.250 | . 222 행신 | 서울 | 5 | 2.0 | 20190716.5 | 7.500 | . 223 행신 | 서울 | 6 | 2.0 | 20190717.5 | 5.000 | . 224 rows × 6 columns . 이제 원하는 출발역과 도착역을 선택하여 요일별 평균 탑승객 수를 살펴보자. . od_average = summary_data[ ( summary_data[&#39;STATION_DEPART&#39;] == &#39;서울&#39; ) &amp; ( summary_data[&#39;STATION_ARRV&#39;] == &#39;부산&#39; )] od_average . STATION_DEPART STATION_ARRV DAYOFWEEK TRAIN_NO DATE NUM_PASSENGER . 98 서울 | 부산 | 0 | 4.333333 | 20190715.0 | 284.800000 | . 99 서울 | 부산 | 1 | 4.333333 | 20190716.0 | 284.266667 | . 100 서울 | 부산 | 2 | 4.333333 | 20190713.5 | 287.833333 | . 101 서울 | 부산 | 3 | 4.333333 | 20190714.5 | 319.500000 | . 102 서울 | 부산 | 4 | 4.333333 | 20190715.5 | 353.833333 | . 103 서울 | 부산 | 5 | 4.333333 | 20190716.5 | 311.166667 | . 104 서울 | 부산 | 6 | 4.333333 | 20190717.5 | 265.083333 | . od_average.plot(x = &quot;DAYOFWEEK&quot;, y = &quot;NUM_PASSENGER&quot;); . 2-4 &#50612;&#47536;&#50773;&#51088; . import matplotlib.pyplot as plt from matplotlib import rc plt.rcParams[&#39;axes.unicode_minus&#39;] = False plt.rcParams[&quot;figure.figsize&quot;] = (10,5) import numpy as np import pandas as pd . import base64 import requests url_data =&quot;https://ilovedata.github.io/teaching/bigdata2/data/little-prince.txt&quot; little_prince = requests.get(url_data) little_prince = little_prince.text . little_prince[:1000] . &#39; r n 어린 왕자 r n 영어동화 (우리말 해석) r n 생텍쥐페리 r n r n r n 헌사(받치는 글) r n 레옹 베르트에게 r n r n 먼저 이 글을 어린이들이 아닌 어른들에게 바치는 것에 대해 사과할까 한다. 심심한 사과의 말을 전한다. 하지만 이들 어른들은 세상에서 가장 좋은 친구다. 물론 이 발언에 대해서도 심심한 사과의 말을 전하는 바이다. 이들 어른들은 모든 걸 이해할 수 있다, 심지어 어린이들의 책까지. 이런 세 번째로 사과의 말을 전하는 바이다. 이들 어른들은 프랑스에만 해도 굶 주림과 추위에 살고 있다. 그에겐 아늑함이 필요한 것도 사실이다. 내 사과들이 충분하든 아니든, 난 이 책을 어른이 된 어린이들에게 바치는 바이다. 모든 어른도 출발은 아이들이었다. 하지만 그들 몇몇만 그걸 기억해낼 뿐이다. 그래 내 헌사(받 치는 글)를 다음과 같이 수정할까 한다. r n 어린이였을 때의 r n 레옹 베르트에게 r n r n ※ 지금부터는 『어린 왕자』(생텍쥐페리의 동화)를 해석해보겠습니다. r n r n 이 동화는 아래 링크의 동화를 우리말로 옮긴 것입니다. r n (번역과정에서 구글 번역기를 이용해 1차로 영어원문으로 만든 다음, 그걸 우리말로 읽을 수 있게 좀 수정하고 다듬은 후, 2차로 우리말로 해석했습니다. 따라서 프랑스어 원문과 다를 수 있습니다. 하지만 성실히 번역했기에 큰 줄거리는 맞다고 생각됩니다. 완전한 해석은 아니라는 점 감안해주시고 읽어주세용~♥ 어린 왕자가 좋아서 해석해본 거예요, 제가 읽으려고요. 그러니 많이 읽어주세요~) r n r n 『어린 왕자』(호주의 애들레이드대학교의 인터넷도서관 사이트)(프랑스 원문) ▶ https://ebooks.adelaide.edu.au/s/saint- exupery/antoine_de/le-petit-prince/ (검색 일자 : 2017-12-9) r n r n r n r n Le Petit Prince r n Le Petit Prince / Antoine de &#39; . type(little_prince) . str . np.char.count(자료, 찾고자 하는 문자열) : 문자열 변수안에 지정된 문자열이 몇 번 나타나는지 세어주는 함수 . np.char.count(little_prince, &quot;별&quot;) . array(159) . &#53581;&#49828;&#53944; &#45208;&#45572;&#44592; . mychar = &quot;폭넓은 교양과 심오한 학문적 이론 및 창의적 전문기술을 지닌 지성인을 기른다. 성실한 근면을 바탕으로 책임과 의무를 다하는 건전한 인격을 갖춘 민주 시민을 기른다.&quot; mychar . &#39;폭넓은 교양과 심오한 학문적 이론 및 창의적 전문기술을 지닌 지성인을 기른다. 성실한 근면을 바탕으로 책임과 의무를 다하는 건전한 인격을 갖춘 민주 시민을 기른다.&#39; . mychar.split(&quot;을&quot;) . [&#39;폭넓은 교양과 심오한 학문적 이론 및 창의적 전문기술&#39;, &#39; 지닌 지성인&#39;, &#39; 기른다. 성실한 근면&#39;, &#39; 바탕으로 책임과 의무를 다하는 건전한 인격&#39;, &#39; 갖춘 민주 시민&#39;, &#39; 기른다.&#39;] . little_prince_chapters = little_prince.split(&#39;어린 왕자 r n&#39;) . little_prince_chapters . final = pd.DataFrame({&quot;chapters&quot; : little_prince_chapters}) final . chapters . 0 r n | . 1 영어동화 (우리말 해석) r n 생텍쥐페리 r n r n r n... | . 2 r n 물론 내 그림은 실제 모습보단 덜해. 그렇다고 내 실수는 아니라고... | . 3 4장 r n r n 난 곧 아주 중요한 두 번째 사실도 알게 됐는데,... | . 4 5장 r n r n 난 매일 그 별과 떠나온 이유와 여행에 대해 알게... | . 5 6장 r n r n 아! 어린 왕자여, 난 이제야 알겠어, 조금씩, ... | . 6 7장 r n r n 다섯 째 날에도, 항상 양 덕분에, 어린 왕자의 ... | . 7 8장 r n r n 나는 곧 이 꽃에 대해 알게 되었다. 어린 왕자의... | . 8 9장 r n 내 생각에, 어린 왕자는, 철새들이 이동할 때 함께 그 별 을... | . 9 10장 r n 어린 왕자의 별 가까이에 소행성 325호, 326호, 327... | . 10 11장 r n r n 두 번째 별엔 허영심쟁이가 살고 있었어요. r ... | . 11 12장 r n r n 술꾼 r n 다음으로 간 별엔 술꾼이 살고 ... | . 12 13장 r n r n 네 번째 별엔 장사꾼이 살고 있었다. 어린 왕자... | . 13 14장 r n r n 다섯 번째 별은 좀 이상했다. 가장 작았기 때문... | . 14 15장 r n r n 여섯 번째 별은 열 배는 큰 별이었다. 거기엔 ... | . 15 16장 r n r n 그리하여 일곱 번째로 들른 별은 지구였다. r ... | . 16 17장 r n r n 뭔 말을 거창하게 하려다 보면, 허풍이 좀 들어... | . 17 18장 r n r n 어린 왕자는 사막을 거닐어보았지만 마주친 거라 ... | . 18 19장 r n r n 어린 왕자는 높은 산에 올랐다. 어린 왕자의 별... | . 19 20장 r n r n 하지만 어린 왕자는 모랫길과 바위와 눈 뿐인 곳을 한... | . 20 21장 r n r n 그런데 그때 여우가 나타났다. r n &quot;안녕... | . 21 &quot;넌 누구니?&quot;라며 어린 왕자가 말했다. &quot;근데 넌 참 귀엽구나...&quot; r ... | . 22 22장 r n r n &quot;안녕하세요.&quot;라며 어린 왕자가 말했다. &quot;안녕... | . 23 23장 r n r n &quot;안녕하세요.&quot;라며 어린 왕자가 말했다. &quot;안녕... | . 24 24장 r n r n 비행기 고장으로 사막에 떨어진지도 이제 여덟째 ... | . 25 25장 r n r n &quot;사람들은,&quot;라며 어린 왕자가 말했다. &quot;서둘러... | . 26 26장 r n r n 그 우물 가 옆엔 무너진 돌담 하나가 있었다. ... | . 27 27장 r n r n 물론 지금은 6년이 지난 얘기다... 난 아직 ... | . &#47928;&#51088;&#50676; &#48712;&#46020; &#44228;&#49328; . counts = final.applymap(lambda x: np.char.count(x, &quot;어린 왕자&quot;)) counts . chapters . 0 0 | . 1 5 | . 2 6 | . 3 7 | . 4 10 | . 5 2 | . 6 5 | . 7 14 | . 8 8 | . 9 24 | . 10 10 | . 11 6 | . 12 11 | . 13 12 | . 14 14 | . 15 0 | . 16 13 | . 17 4 | . 18 7 | . 19 8 | . 20 1 | . 21 23 | . 22 6 | . 23 3 | . 24 12 | . 25 15 | . 26 20 | . 27 12 | . counts.plot(); . &#49892;&#49845; 1. &#52309;&#53552;&#48324;&#47196; &#50668;&#50864;, ?, !&#51032; &#48712;&#46020;&#47484; &#44228;&#49328;&#54616;&#44256; &#44536;&#47548;&#51004;&#47196; &#45208;&#53440;&#45236;&#50612;&#46972;. . counts_fox = final.applymap(lambda x : np.char.count(x, &quot;여우&quot;)) counts_fox . chapters . 0 0 | . 1 0 | . 2 0 | . 3 0 | . 4 0 | . 5 0 | . 6 0 | . 7 0 | . 8 0 | . 9 0 | . 10 0 | . 11 0 | . 12 0 | . 13 0 | . 14 0 | . 15 0 | . 16 0 | . 17 0 | . 18 0 | . 19 0 | . 20 3 | . 21 30 | . 22 0 | . 23 0 | . 24 4 | . 25 2 | . 26 0 | . 27 0 | . counts_fox.plot() . &lt;AxesSubplot:&gt; . counts_n = final.applymap(lambda x: np.char.count(x, &quot;!&quot;)) counts_n . chapters . 0 0 | . 1 2 | . 2 11 | . 3 4 | . 4 7 | . 5 3 | . 6 19 | . 7 9 | . 8 1 | . 9 18 | . 10 5 | . 11 1 | . 12 9 | . 13 6 | . 14 14 | . 15 1 | . 16 4 | . 17 0 | . 18 1 | . 19 2 | . 20 0 | . 21 16 | . 22 0 | . 23 0 | . 24 3 | . 25 8 | . 26 17 | . 27 8 | . counts_n.plot() . &lt;AxesSubplot:&gt; . counts_m = final.applymap(lambda x: np.char.count(x, &quot;?&quot;)) counts_m . chapters . 0 0 | . 1 2 | . 2 10 | . 3 7 | . 4 4 | . 5 2 | . 6 7 | . 7 3 | . 8 1 | . 9 11 | . 10 5 | . 11 4 | . 12 20 | . 13 6 | . 14 16 | . 15 0 | . 16 5 | . 17 2 | . 18 5 | . 19 1 | . 20 0 | . 21 13 | . 22 5 | . 23 2 | . 24 2 | . 25 5 | . 26 7 | . 27 2 | . counts_m.plot() . &lt;AxesSubplot:&gt; .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/09/29/(d%EA%B0%9C%EB%A1%A0-2-1~2-4).html",
            "relUrl": "/python/2022/09/29/(d%EA%B0%9C%EB%A1%A0-2-1~2-4).html",
            "date": " • Sep 29, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "데이터 시각화 과제 3",
            "content": "import numpy as np import matplotlib.pyplot as plt import pandas as pd . np.random.seed(43052) ϵ = np.random.randn(100) . plt.plot(np.arange(1,101),ϵ,&#39;--o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc76a280580&gt;] . (1) $ epsilon_t$ 와 $ epsilon_{t-1}$은 독립이라고 보여지는가? . 독립이다. . (2) 아래의 수식을 만족하는 벡터 ${ boldsymbol y} = (y_1,y_2, dots, y_{100})$ 을 생성하라. (단 $y_1= epsilon_1$) . $$ y_t = y_{t-1} + epsilon_t$$ . y = np.cumsum(ϵ) #y는 입실론을 다 더한 것 . plt.plot(y,&#39;--o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7180cdcd0&gt;] . (3) $(t,y_t)$의 dot-connected plot을 그려라. . ϵ1 = ϵ[:-1] #t-1의 시점 ϵ2 = ϵ[1:] #t의 시점 . y1 = y[:-1] #t-1의 시점 y2 = y[1:] #t의 시점 . plt.plot(y1, y2, &#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc7395b9fa0&gt;] . (4) $y_t$와 $y_{t-1}$은 독립이라고 볼 수 있는가? . np.corrcoef(y1, y2) . array([[1. , 0.97237553], [0.97237553, 1. ]]) . $y_{t-1}$이 변할 때 $y_t$가 변하므로 독립이 아니다. .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/09/27/%EA%B3%BC%EC%A0%9C3(%EC%96%B4%EB%A0%A4%EC%9B%80).html",
            "relUrl": "/python/2022/09/27/%EA%B3%BC%EC%A0%9C3(%EC%96%B4%EB%A0%A4%EC%9B%80).html",
            "date": " • Sep 27, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "데이터 시각화4",
            "content": "",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/09/23/.html",
            "relUrl": "/python/2022/09/23/.html",
            "date": " • Sep 23, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "데이터 시각화3",
            "content": "&#47928;&#51228;1 . import matplotlib.pyplot as plt import numpy as np . fig, axs = plt.subplots(2, 3) . x,y = [1,2,3,4], [1,2,4,3] axs[0,0].plot(x, y,&#39;or&#39;) axs[1,0].plot(x, y,&#39;--or&#39;) axs[0,1].plot(x, y,&#39;og&#39;) axs[1,1].plot(x, y,&#39;--og&#39;) axs[0,2].plot(x, y,&#39;ob&#39;) axs[1,2].plot(x, y,&#39;--ob&#39;) fig . &#47928;&#51228;2 . fig = plt.figure() ax1 = fig.add_axes([0.5,0.5,1,1]) # (0,0)의 위치에 (1,1)인 액시즈(=네모틀)을 만들어라. ax2 = fig.add_axes([1.0,1.0,1,1]) ax3 = fig.add_axes([1.5,1.5,1,1]) ax1,ax2,ax3 = fig.axes fig.axes . [&lt;Axes:&gt;, &lt;Axes:&gt;, &lt;Axes:&gt;] . x,y = [1,2,3,4], [1,2,1,1] ax1.plot(x, y, &quot;or&quot;) ax2.plot(x, y, &quot;og&quot;) ax3.plot(x, y, &quot;ob&quot;) fig . &#47928;&#51228; 3 . x = np.arange(-5,5,0.1) y1 = np.sin(x) y2 = np.sin(2*x) + 2 y3 = np.sin(4*x) + 4 y4 = np.sin(8*x) + 6 . plt.plot(x, y1, &quot;--r&quot;) plt.plot(x, y2, &quot;--g&quot;) plt.plot(x, y3, &quot;--b&quot;) plt.plot(x, y4, &quot;--m&quot;) . [&lt;matplotlib.lines.Line2D at 0x7fd28a798400&gt;] .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/09/22/fig-axes.html",
            "relUrl": "/python/2022/09/22/fig-axes.html",
            "date": " • Sep 22, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "데이터 시각화2",
            "content": "!pip install opencv-python . Requirement already satisfied: opencv-python in /Users/heji/opt/anaconda3/lib/python3.9/site-packages (4.6.0.66) Requirement already satisfied: numpy&gt;=1.19.3 in /Users/heji/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.21.5) . import cv2 import matplotlib.pyplot as plt import pandas as pd import numpy as np . Collecting opencv-python Downloading opencv_python-4.6.0.66-cp36-abi3-macosx_10_15_x86_64.whl (46.4 MB) |████████████████████████████████| 46.4 MB 613 kB/s eta 0:00:01 Requirement already satisfied: numpy&gt;=1.17.3 in /Users/heji/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.21.5) Installing collected packages: opencv-python Successfully installed opencv-python-4.6.0.66 . #drive.mount(&#39;/content/drive&#39;) . !wget https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png img =cv2.imread(&#39;hw_img.png&#39;) . --2022-09-23 16:22:35-- https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 120618 (118K) [image/png] Saving to: &#39;hw_img.png&#39; hw_img.png 100%[===================&gt;] 117.79K --.-KB/s in 0.02s 2022-09-23 16:22:36 (7.03 MB/s) - &#39;hw_img.png&#39; saved [120618/120618] . img.shape . (531, 468, 3) . plt.imshow(img) . &lt;matplotlib.image.AxesImage at 0x7ff292852eb0&gt; . img_red = img * 0 img_green = img * 0 img_blue = img * 0 . img_red[...,0] = img[...,0] #이미지 색 분리하기 img_green[...,1] = img[...,1] img_blue[...,2] = img[...,2] . plt.imshow(img_red) . &lt;matplotlib.image.AxesImage at 0x7ff2723f8e50&gt; . img_red[:,:,0].shape . (531, 468) . plt.hist(img[:,:,0].reshape(-1)) #색의 히스토그램 그리기 . (array([ 369., 1419., 2494., 3906., 33232., 71030., 60306., 17593., 39230., 18929.]), array([ 28., 45., 62., 79., 96., 113., 130., 147., 164., 181., 198.]), &lt;BarContainer object of 10 artists&gt;) . _fig = plt.hist(img[:,:,0].reshape(-1),bins=255, range=[0,255]) #색의 범위는 0~255 . img2_red = cv2.equalizeHist(img[...,0]) plt.hist(img2_red.reshape(-1)) #히스토그램 평탄화작업 . (array([22189., 25646., 25483., 21440., 26638., 24418., 26942., 25299., 24005., 26448.]), array([ 0. , 25.5, 51. , 76.5, 102. , 127.5, 153. , 178.5, 204. , 229.5, 255. ]), &lt;BarContainer object of 10 artists&gt;) . _fig=plt.hist(img2_red.reshape(-1),bins=255,range=(0,255)) #검은색에서 하양색까지 색을 골고루 쓰게끔 . img2 = np.stack([img2_red,img2_red,img2_red],axis=-1) #빨강 이미지 세개 쌓기 . img2.shape . (531, 468, 3) . plt.imshow(img2) . &lt;matplotlib.image.AxesImage at 0x7ff292d21c40&gt; . plt.imshow(img) #원래 이미지, 회색 빛 . &lt;matplotlib.image.AxesImage at 0x7ff292c8ee50&gt; . 처음부터 흑백으로 불러오기 . img_black =cv2.imread(&#39;hw_img.png&#39;, 0) #흑백 버전으로 그림 불러오기 . img_black2 = cv2.equalizeHist(img_black) . plt.imshow(img_black2, cmap = &#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7ff280356af0&gt; . plt.imshow(np.concatenate([img_black,img_black2],axis=1),cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7ff2a079d310&gt; .",
            "url": "https://g-gg-ggg.github.io/Oppps/python/2022/09/14/%EA%B3%BC%EC%A0%9C_%ED%9E%88%EC%8A%A4%ED%86%A0%EA%B7%B8%EB%9E%A8_%EC%9D%B4%ED%80%84%EB%9D%BC%EC%9D%B4%EC%A0%9C%EC%9D%B4%EC%85%98.html",
            "relUrl": "/python/2022/09/14/%EA%B3%BC%EC%A0%9C_%ED%9E%88%EC%8A%A4%ED%86%A0%EA%B7%B8%EB%9E%A8_%EC%9D%B4%ED%80%84%EB%9D%BC%EC%9D%B4%EC%A0%9C%EC%9D%B4%EC%85%98.html",
            "date": " • Sep 14, 2022"
        }
        
    
  
    
        ,"post20": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://g-gg-ggg.github.io/Oppps/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post21": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://g-gg-ggg.github.io/Oppps/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "it’s me . listener | writer | student | . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://g-gg-ggg.github.io/Oppps/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://g-gg-ggg.github.io/Oppps/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}